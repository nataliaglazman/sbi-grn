{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MCMC_newmodel_3params import run_chain\n",
    "import multiprocessing\n",
    "def run_parallel_chains(true_params, num_iterations, num_chains):\n",
    "    pool = multiprocessing.Pool(processes=num_chains)\n",
    "    args_list = [(true_params, num_iterations, i) for i in range(num_chains)]\n",
    "    results = pool.map(run_chain, args_list)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    chain_accepted_parameters = [result[0] for result in results]\n",
    "    counts = [result[1] for result in results]\n",
    "    dists = [result[2] for result in results]\n",
    "    return chain_accepted_parameters, counts, dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000th iterations done, previously acceptance rate = 0.5522, threshold is set to 589.2125345094432\n",
      "10000th iterations done, previously acceptance rate = 1.9998, threshold is set to 649.4694862915196\n",
      "10000th iterations done, previously acceptance rate = 0.9999, threshold is set to 664.9395310459961\n",
      "15000th iterations done, previously acceptance rate = 0.4716, threshold is set to 471.1726611438824\n",
      "10000th iterations done, previously acceptance rate = 0.9999, threshold is set to 661.3902483143186\n",
      "20000th iterations done, previously acceptance rate = 0.4282, threshold is set to 406.0047281019718\n",
      "20000th iterations done, previously acceptance rate = 1.1156, threshold is set to 600.5409204195926\n",
      "20000th iterations done, previously acceptance rate = 0.6607, threshold is set to 617.5794224948676\n",
      "25000th iterations done, previously acceptance rate = 0.4766, threshold is set to 319.26409700029876\n",
      "20000th iterations done, previously acceptance rate = 0.6386, threshold is set to 616.5686889362164\n",
      "30000th iterations done, previously acceptance rate = 0.5304, threshold is set to 243.3943041241007\n",
      "30000th iterations done, previously acceptance rate = 0.9, threshold is set to 501.1179774493629\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ap,c,d\u001b[38;5;241m=\u001b[39m\u001b[43mrun_parallel_chains\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrue_params\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m50000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[47], line 6\u001b[0m, in \u001b[0;36mrun_parallel_chains\u001b[0;34m(true_params, num_iterations, num_chains)\u001b[0m\n\u001b[1;32m      4\u001b[0m pool \u001b[38;5;241m=\u001b[39m multiprocessing\u001b[38;5;241m.\u001b[39mPool(processes\u001b[38;5;241m=\u001b[39mnum_chains)\n\u001b[1;32m      5\u001b[0m args_list \u001b[38;5;241m=\u001b[39m [(true_params, num_iterations, i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_chains)]\n\u001b[0;32m----> 6\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_chain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m pool\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m      8\u001b[0m pool\u001b[38;5;241m.\u001b[39mjoin()\n",
      "File \u001b[0;32m~/Documents/Uni/PostGrad/Project_1/.conda/lib/python3.11/multiprocessing/pool.py:367\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    363\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Uni/PostGrad/Project_1/.conda/lib/python3.11/multiprocessing/pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    770\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Uni/PostGrad/Project_1/.conda/lib/python3.11/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Uni/PostGrad/Project_1/.conda/lib/python3.11/threading.py:629\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    627\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 629\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/Documents/Uni/PostGrad/Project_1/.conda/lib/python3.11/threading.py:327\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 327\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000th iterations done, previously acceptance rate = 0.4764, threshold is set to 528.4513340802852\n",
      "35000th iterations done, previously acceptance rate = 0.5022, threshold is set to 188.8142530466227\n",
      "30000th iterations done, previously acceptance rate = 0.4487, threshold is set to 543.441296327315\n",
      "40000th iterations done, previously acceptance rate = 0.4694, threshold is set to 156.2059089217339\n"
     ]
    }
   ],
   "source": [
    "ap,c,d=run_parallel_chains(true_params,50000,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import numpy as np\n",
    "\n",
    "from MCMC_newmodel_3params import run_chain1\n",
    "result_list = []\n",
    "def append_result(result):\n",
    "    # This is called whenever foo_pool(i) returns a result.\n",
    "    # result_list is modified only by the main process, not the pool workers.\n",
    "    result_list.append(result)\n",
    "\n",
    "def run_parallel_chains(true_params, num_iterations, num_chains):\n",
    "    chain_parameters = [[(true_params, num_iterations)] for _ in range(num_chains)]\n",
    "    # Create a multiprocessing Pool\n",
    "    with multiprocessing.Pool() as pool:\n",
    "        # Use pool.map to run the chains in parallel\n",
    "        results = pool.starmap(run_chain1, chain_parameters)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    params=np.array([result[0] for result in results])\n",
    "    acceptance=np.array([result[1] for result in results])\n",
    "    distance=np.array([result[2] for result in results])\n",
    "    return(params, acceptance, distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000th iterations done, previously acceptance rate = 0.0, threshold is set to 600\n",
      "10000th iterations done, previously acceptance rate = 0.8941, threshold is set to 443.14635890395346\n",
      "10000th iterations done, previously acceptance rate = 0.8898, threshold is set to 440.4235574630973\n",
      "10000th iterations done, previously acceptance rate = 0.8876, threshold is set to 464.36760982516284\n",
      "20000th iterations done, previously acceptance rate = 0.4069, threshold is set to 340.08020601973817\n",
      "20000th iterations done, previously acceptance rate = 0.0, threshold is set to 600\n",
      "20000th iterations done, previously acceptance rate = 0.4099, threshold is set to 334.9925165059373\n",
      "20000th iterations done, previously acceptance rate = 0.4366, threshold is set to 373.93072871241026\n",
      "30000th iterations done, previously acceptance rate = 0.4281, threshold is set to 225.48510206913696\n",
      "30000th iterations done, previously acceptance rate = 0.0, threshold is set to 600\n",
      "30000th iterations done, previously acceptance rate = 0.4248, threshold is set to 222.43278528365374\n",
      "30000th iterations done, previously acceptance rate = 0.4353, threshold is set to 250.69570411438843\n",
      "40000th iterations done, previously acceptance rate = 0.4496, threshold is set to 158.8802187105851\n",
      "40000th iterations done, previously acceptance rate = 0.459, threshold is set to 155.31409136096573\n",
      "40000th iterations done, previously acceptance rate = 0.0, threshold is set to 600\n",
      "40000th iterations done, previously acceptance rate = 0.4563, threshold is set to 174.77488923454615\n"
     ]
    }
   ],
   "source": [
    "pa, ac, di=run_parallel_chains(true_params=[200.,200.,200.], num_iterations=50000, num_chains=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mresults\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Posterior Checks as SBIBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The median distance should be considered a mere check rather than a metric and it\n",
    "does not necessarily test the structure of the estimated posterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Median L2 distance from posterior samples and x_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "def median_distance(\n",
    "    predictive_samples: torch.Tensor,\n",
    "    observation: torch.Tensor,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Compute median distance\n",
    "\n",
    "    Uses NumPy implementation, see [1] for discussion of differences.\n",
    "\n",
    "    Args:\n",
    "        predictive_samples: Predictive samples\n",
    "        observation: Observation\n",
    "\n",
    "    Returns:\n",
    "        Median distance\n",
    "\n",
    "    [1]: https://github.com/pytorch/pytorch/issues/1837\n",
    "    \"\"\"\n",
    "    assert predictive_samples.ndim == 2\n",
    "    assert observation.ndim == 2\n",
    "\n",
    "    l2_distance = torch.norm((observation - predictive_samples), dim=-1)\n",
    "    return torch.tensor([np.median(l2_distance.numpy()).astype(np.float32)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
