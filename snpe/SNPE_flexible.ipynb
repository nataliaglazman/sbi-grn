{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNPE flexible "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from sbi.inference import SNPE, prepare_for_sbi, simulate_for_sbi\n",
    "from sbi.utils.get_nn_models import posterior_nn\n",
    "from sbi import utils as utils\n",
    "from sbi import analysis as analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define simulator and prior\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import odeint\n",
    "\n",
    "# Define the model\n",
    "def model(variables, t, params):\n",
    "    m1, p1, m2, p2, m3, p3 = variables\n",
    "    k1, k2 = params\n",
    "\n",
    "    dm1dt = -m1 + (10 ** 3 / (1 + (10 ** k1 * p2) ** 2)) + 1\n",
    "    dp1dt = -10 ** 0 * (p1 - m1)\n",
    "\n",
    "    dm2dt = -m2 + (10 ** 3 / (1 + (10 ** k2 * p3) ** 2)) + 1\n",
    "    dp2dt = -10 ** 0 * (p2 - m2)\n",
    "\n",
    "    dm3dt = -m3 + (10 ** 3 / (1 + (10 ** 0 * p1) ** 2)) + 1\n",
    "    dp3dt = -10 ** 0 * (p3 - m3)\n",
    "\n",
    "    return [dm1dt, dp1dt, dm2dt, dp2dt, dm3dt, dp3dt]\n",
    "\n",
    "#Define true parameters\n",
    "true_params = np.array([\n",
    "    0, 0  # first set of odes\n",
    "])\n",
    "\n",
    "def ode_solver(parameter_set):\n",
    "    initial_conditions = np.array([0, 1, 0, 3, 0, 2])\n",
    "    t = np.linspace(0, 100, 1000) #num_timesteps is 1000\n",
    "    solution = odeint(model, initial_conditions, t, args=(parameter_set,))\n",
    "    return solution\n",
    "\n",
    "true_data = ode_solver(true_params) #True trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dim = 2\n",
    "prior = utils.BoxUniform(low=-3 * torch.ones(num_dim), high=3 * torch.ones(num_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with SNPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/home23/sg2023/Desktop/SBI/.conda/lib/python3.11/site-packages/scipy/integrate/_odepack_py.py:242: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  output = _odepack.odeint(func, y0, t, args, Dfun, col_deriv, ml, mu,\n"
     ]
    }
   ],
   "source": [
    "simulator, prior = prepare_for_sbi(ode_solver, prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate the inference object:\n",
    "inference = SNPE(prior=prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bc9feddf5a2492eac5b4a9066ba971d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 500 simulations.:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "theta, x = simulate_for_sbi(simulator, proposal=prior, num_simulations=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference = inference.append_simulations(theta, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sbi.inference.snpe.snpe_c.SNPE_C at 0x7f6995828410>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.0000,   1.0000,   0.0000,   3.0000,   0.0000,   2.0000],\n",
       "        [  8.9123,   1.3648,  12.9051,   3.4811,  42.9083,   4.0501],\n",
       "        [ 13.8703,   2.3506,  14.4150,   4.4862,  61.6269,   8.8289],\n",
       "        ...,\n",
       "        [ 46.9959, 113.7526,  56.8882,  25.9989,   1.2610,   2.7314],\n",
       "        [ 42.7398, 107.1846,  63.3755,  29.2513,   1.2439,   2.5905],\n",
       "        [ 38.8630, 100.8554,  70.3635,  32.8362,   1.2295,   2.4615]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_o = torch.tensor(true_data)\n",
    "x_o\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network successfully converged after 108 epochs.\n"
     ]
    }
   ],
   "source": [
    "density_estimator = inference.train()\n",
    "posterior = inference.build_posterior(density_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'posterior' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mposterior\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'posterior' is not defined"
     ]
    }
   ],
   "source": [
    "posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The `x` passed to condition the posterior for evaluation or sampling\n                has an inferred batch shape larger than one. This is not supported in\n                some sbi methods for reasons depending on the scenario:\n\n                    - in case you want to evaluate or sample conditioned on several xs\n                    e.g., (p(theta | [x1, x2, x3])), this is not supported yet except\n                    when using likelihood based SNLE and SNRE.\n\n                    - in case you trained with a single round to do amortized inference\n                    and now you want to evaluate or sample a given theta conditioned on\n                    several xs, one after the other, e.g, p(theta | x1), p(theta | x2),\n                    p(theta| x3): this broadcasting across xs is not supported in sbi.\n                    Instead, what you can do it to call posterior.log_prob(theta, xi)\n                    multiple times with different xi.\n\n                    - finally, if your observation is multidimensional, e.g., an image,\n                    make sure to pass it with a leading batch dimension, e.g., with\n                    shape (1, xdim1, xdim2). Beware that the current implementation\n                    of sbi might not provide stable support for this and result in\n                    shape mismatches.\n\n            NOTE: below we use list notation to reduce clutter, but `x` should be of \n            type torch.Tensor or ndarray.\n\n            For example:\n\n            > x_o = [[1]]\n            > x_o = [[1, 2, 3]]\n\n            are interpreted as single observations with a leading batch dimension of\n            one. However\n\n            > x_o = [ [1], [2] ]\n            > x_o = [ [1,2,3], [4,5,6] ]\n\n            are interpreted as a batch of two scalar or vector observations, which\n            is not supported yet. The following is interpreted as a matrix-shaped\n            observation, e.g. a monochromatic image:\n\n            > x_o = [ [[1,2,3], [4,5,6]] ]\n\n            Finally, for convenience,\n\n            > x_o = [1]\n            > x_o = [1, 2, 3]\n\n            will be interpreted as a single scalar or single vector observation\n            respectively, without the user needing to wrap or unsqueeze them.\n            ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m posterior_samples \u001b[38;5;241m=\u001b[39m \u001b[43mposterior\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_o\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/SBI/.conda/lib/python3.11/site-packages/sbi/inference/posteriors/direct_posterior.py:344\u001b[0m, in \u001b[0;36mDirectPosterior.sample\u001b[0;34m(self, sample_shape, x, show_progress_bars, sample_with, mcmc_method, mcmc_parameters, rejection_sampling_parameters, sample_with_mcmc)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m    342\u001b[0m sample_with \u001b[38;5;241m=\u001b[39m sample_with \u001b[38;5;28;01mif\u001b[39;00m sample_with \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sample_with\n\u001b[0;32m--> 344\u001b[0m x, num_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_for_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m potential_fn_provider \u001b[38;5;241m=\u001b[39m PotentialFunctionProvider()\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_with \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmcmc\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/SBI/.conda/lib/python3.11/site-packages/sbi/inference/posteriors/base_posterior.py:387\u001b[0m, in \u001b[0;36mNeuralPosterior._prepare_for_sample\u001b[0;34m(self, x, sample_shape)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;124;03mReturn checked, reshaped, potentially default values for `x` and `sample_shape`.\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;124;03m    samples.\u001b[39;00m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;66;03m# Select and check x to condition on.\u001b[39;00m\n\u001b[0;32m--> 387\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_x_else_default_x\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    388\u001b[0m num_samples \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mSize(sample_shape)\u001b[38;5;241m.\u001b[39mnumel()\n\u001b[1;32m    390\u001b[0m \u001b[38;5;66;03m# Move x to current device.\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/SBI/.conda/lib/python3.11/site-packages/sbi/inference/posteriors/base_posterior.py:920\u001b[0m, in \u001b[0;36mNeuralPosterior._x_else_default_x\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_x_else_default_x\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Optional[Array]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Array:\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 920\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprocess_x\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_x_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_iid_x\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_allow_iid_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    922\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    923\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContext `x` needed when a default has not been set.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    924\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf you\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124md like to have a default, use the `.set_default_x()` method.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    925\u001b[0m         )\n",
      "File \u001b[0;32m~/Desktop/SBI/.conda/lib/python3.11/site-packages/sbi/utils/user_input_checks.py:474\u001b[0m, in \u001b[0;36mprocess_x\u001b[0;34m(x, x_shape, allow_iid_x)\u001b[0m\n\u001b[1;32m    472\u001b[0m input_x_shape \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    473\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_iid_x:\n\u001b[0;32m--> 474\u001b[0m     \u001b[43mcheck_for_possibly_batched_x_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_x_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    475\u001b[0m     start_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/SBI/.conda/lib/python3.11/site-packages/sbi/utils/user_input_checks.py:227\u001b[0m, in \u001b[0;36mcheck_for_possibly_batched_x_shape\u001b[0;34m(x_shape)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;66;03m# Reject multidimensional data with batch_shape > 1.\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x_ndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m inferred_batch_shape \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 227\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    228\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124;03m\"\"\"The `x` passed to condition the posterior for evaluation or sampling\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;124;03m            has an inferred batch shape larger than one. This is not supported in\u001b[39;00m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;124;03m            some sbi methods for reasons depending on the scenario:\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \n\u001b[1;32m    232\u001b[0m \u001b[38;5;124;03m                - in case you want to evaluate or sample conditioned on several xs\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;124;03m                e.g., (p(theta | [x1, x2, x3])), this is not supported yet except\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;124;03m                when using likelihood based SNLE and SNRE.\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \n\u001b[1;32m    236\u001b[0m \u001b[38;5;124;03m                - in case you trained with a single round to do amortized inference\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;124;03m                and now you want to evaluate or sample a given theta conditioned on\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;124;03m                several xs, one after the other, e.g, p(theta | x1), p(theta | x2),\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;124;03m                p(theta| x3): this broadcasting across xs is not supported in sbi.\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;124;03m                Instead, what you can do it to call posterior.log_prob(theta, xi)\u001b[39;00m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;124;03m                multiple times with different xi.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m \n\u001b[1;32m    243\u001b[0m \u001b[38;5;124;03m                - finally, if your observation is multidimensional, e.g., an image,\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;124;03m                make sure to pass it with a leading batch dimension, e.g., with\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;124;03m                shape (1, xdim1, xdim2). Beware that the current implementation\u001b[39;00m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;124;03m                of sbi might not provide stable support for this and result in\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;124;03m                shape mismatches.\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \n\u001b[1;32m    249\u001b[0m \u001b[38;5;124;03m        NOTE: below we use list notation to reduce clutter, but `x` should be of \u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;124;03m        type torch.Tensor or ndarray.\u001b[39;00m\n\u001b[1;32m    251\u001b[0m \n\u001b[1;32m    252\u001b[0m \u001b[38;5;124;03m        For example:\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \n\u001b[1;32m    254\u001b[0m \u001b[38;5;124;03m        > x_o = [[1]]\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;124;03m        > x_o = [[1, 2, 3]]\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \n\u001b[1;32m    257\u001b[0m \u001b[38;5;124;03m        are interpreted as single observations with a leading batch dimension of\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;124;03m        one. However\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \n\u001b[1;32m    260\u001b[0m \u001b[38;5;124;03m        > x_o = [ [1], [2] ]\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;124;03m        > x_o = [ [1,2,3], [4,5,6] ]\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \n\u001b[1;32m    263\u001b[0m \u001b[38;5;124;03m        are interpreted as a batch of two scalar or vector observations, which\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;124;03m        is not supported yet. The following is interpreted as a matrix-shaped\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;124;03m        observation, e.g. a monochromatic image:\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \n\u001b[1;32m    267\u001b[0m \u001b[38;5;124;03m        > x_o = [ [[1,2,3], [4,5,6]] ]\u001b[39;00m\n\u001b[1;32m    268\u001b[0m \n\u001b[1;32m    269\u001b[0m \u001b[38;5;124;03m        Finally, for convenience,\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \n\u001b[1;32m    271\u001b[0m \u001b[38;5;124;03m        > x_o = [1]\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;124;03m        > x_o = [1, 2, 3]\u001b[39;00m\n\u001b[1;32m    273\u001b[0m \n\u001b[1;32m    274\u001b[0m \u001b[38;5;124;03m        will be interpreted as a single scalar or single vector observation\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03m        respectively, without the user needing to wrap or unsqueeze them.\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;03m        \"\"\"\u001b[39;00m\n\u001b[1;32m    277\u001b[0m     )\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: The `x` passed to condition the posterior for evaluation or sampling\n                has an inferred batch shape larger than one. This is not supported in\n                some sbi methods for reasons depending on the scenario:\n\n                    - in case you want to evaluate or sample conditioned on several xs\n                    e.g., (p(theta | [x1, x2, x3])), this is not supported yet except\n                    when using likelihood based SNLE and SNRE.\n\n                    - in case you trained with a single round to do amortized inference\n                    and now you want to evaluate or sample a given theta conditioned on\n                    several xs, one after the other, e.g, p(theta | x1), p(theta | x2),\n                    p(theta| x3): this broadcasting across xs is not supported in sbi.\n                    Instead, what you can do it to call posterior.log_prob(theta, xi)\n                    multiple times with different xi.\n\n                    - finally, if your observation is multidimensional, e.g., an image,\n                    make sure to pass it with a leading batch dimension, e.g., with\n                    shape (1, xdim1, xdim2). Beware that the current implementation\n                    of sbi might not provide stable support for this and result in\n                    shape mismatches.\n\n            NOTE: below we use list notation to reduce clutter, but `x` should be of \n            type torch.Tensor or ndarray.\n\n            For example:\n\n            > x_o = [[1]]\n            > x_o = [[1, 2, 3]]\n\n            are interpreted as single observations with a leading batch dimension of\n            one. However\n\n            > x_o = [ [1], [2] ]\n            > x_o = [ [1,2,3], [4,5,6] ]\n\n            are interpreted as a batch of two scalar or vector observations, which\n            is not supported yet. The following is interpreted as a matrix-shaped\n            observation, e.g. a monochromatic image:\n\n            > x_o = [ [[1,2,3], [4,5,6]] ]\n\n            Finally, for convenience,\n\n            > x_o = [1]\n            > x_o = [1, 2, 3]\n\n            will be interpreted as a single scalar or single vector observation\n            respectively, without the user needing to wrap or unsqueeze them.\n            "
     ]
    }
   ],
   "source": [
    "posterior_samples = posterior.sample((10000,), x=x_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
