{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulations with RNN with odeint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is not available. Using CPU.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    # Set the device to GPU\n",
    "    device = torch.device(\"cuda\")\n",
    "    # This will make sure that tensors and models created will be moved to GPU\n",
    "    torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "    print(\"GPU is available.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU is not available. Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import odeint\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sbi.inference import SNPE, prepare_for_sbi, simulate_for_sbi\n",
    "from sbi import utils as utils\n",
    "from sbi import analysis as analysis\n",
    "from sbi.inference.base import infer\n",
    "import numpy as np\n",
    "\n",
    "# Old simulator without loops...\n",
    "def model(variables, t, params):\n",
    "\n",
    "    m1, p1, m2, p2, m3, p3 = variables\n",
    "    k1, k2, k3 = params #only 3 ks are parameters to infer\n",
    "    a1 = a2 = a3 = 24.78485282457379\n",
    "    g1 = g2 = g3 = 0.024884149937163258\n",
    "    n1 = n2 = n3 = 5\n",
    "    b1 = b2 = b3 = 33.82307682700831\n",
    "    dm1 = dm2 = dm3 = 1.143402097500176\n",
    "    dp1 = dp2 = dp3 = 0.7833664565550977\n",
    "\n",
    "    dm1dt = -dm1 * m1 + (a1 / (1 + ((1/k1) * p2) ** n1)) + g1\n",
    "    dp1dt = (b1 * m1) - (dp1 * p1)\n",
    "    dm2dt = -dm2 * m2 + (a2 / (1 + ((1/k2) * p3) ** n2)) + g2\n",
    "    dp2dt = (b2 * m2) - (dp2 * p2)\n",
    "    dm3dt = -dm3 * m3 + (a3 / (1 + ((1/k3) * p1) ** n3)) + g3\n",
    "    dp3dt = (b3 * m3)-(dp3 * p3)\n",
    "    \n",
    "    return [dm1dt, dp1dt, dm2dt, dp2dt, dm3dt, dp3dt]\n",
    "\n",
    "# Initial conditions\n",
    "true_params = torch.tensor([\n",
    "    246.96291990024542, 246.96291990024542, 246.96291990024542])\n",
    "num_timesteps = 100\n",
    "num_trajectories = 6\n",
    "y0 = np.array([0, 1, 0, 3, 0, 2])\n",
    "t = np.linspace(0, 100, num_timesteps)\n",
    "\n",
    "def simulator(params):\n",
    "    y = odeint(model, y0, t, args=(params,))\n",
    "    traj = torch.tensor(y, dtype=torch.float32).flatten()\n",
    "    return traj.view(100,6)\n",
    "\n",
    "true_data = simulator(true_params)\n",
    "    \n",
    "num_dim = 3\n",
    "prior = utils.BoxUniform(low=10**-2 * torch.ones(num_dim), high=250 * torch.ones(num_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 6])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator_wrapper, prior = prepare_for_sbi(simulator, prior)\n",
    "batch_size = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 100, 6])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fourdim = simulator_wrapper(prior.sample((batch_size,)))\n",
    "fourdim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs (torch.cuda.device_count()): 0\n",
      "Number of CPUs (multiprocessing.cpu_count()): 8\n",
      "Number of CPUs (os.cpu_count()): 8\n"
     ]
    }
   ],
   "source": [
    "### IMPORT PACKAGES AND ALSO REWRITE FUNCTIONS ###\n",
    "\n",
    "import torch\n",
    "import multiprocessing\n",
    "import os\n",
    "\n",
    "def get_gpu_count():\n",
    "    return torch.cuda.device_count()\n",
    "\n",
    "def get_cpu_count():\n",
    "    return multiprocessing.cpu_count()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    num_gpus = get_gpu_count()\n",
    "    num_cpus = get_cpu_count()\n",
    "    print(\"Number of GPUs (torch.cuda.device_count()):\", num_gpus)\n",
    "    print(\"Number of CPUs (multiprocessing.cpu_count()):\", num_cpus)\n",
    "\n",
    "print(\"Number of CPUs (os.cpu_count()):\", os.cpu_count())\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import odeint\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sbi.inference import SNPE, prepare_for_sbi, simulate_for_sbi\n",
    "from sbi import utils as utils\n",
    "from sbi import analysis as analysis\n",
    "from sbi.inference.base import infer\n",
    "import numpy as np\n",
    "\n",
    "import joblib\n",
    "import math\n",
    "from math import ceil\n",
    "import random\n",
    "import contextlib\n",
    "import torch\n",
    "import sys\n",
    "from numpy import fft, ndarray\n",
    "from scipy.stats import norm\n",
    "import os\n",
    "import seaborn as sns\n",
    "from pyro.infer.mcmc.api import MCMC\n",
    "from warnings import warn\n",
    "from torch import Tensor, split, randint, cat\n",
    "from typing import Any, Callable, Optional, Tuple, Union, Dict\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "from tqdm.auto import tqdm, trange\n",
    "from pyro.infer.mcmc import HMC, NUTS\n",
    "from sbi.inference import prepare_for_sbi, SNLE\n",
    "from sbi import utils as utils\n",
    "from sbi import analysis as analysis\n",
    "from sbi.types import Shape, TorchTransform\n",
    "from sbi.utils.get_nn_models import (likelihood_nn,)\n",
    "from sbi.samplers.mcmc import SliceSamplerVectorized\n",
    "from sbi.samplers.mcmc.slice_numpy import MCMCSampler\n",
    "from sbi.utils import tensor2numpy\n",
    "\n",
    "def seed_all_backends(seed: Optional[Union[int, Tensor]] = None) -> None:\n",
    "    if seed is None:\n",
    "        seed = int(torch.randint(10_000_000, size=(1,)))\n",
    "    else:\n",
    "        # Cast Tensor to int (required by math.random since Python 3.11)\n",
    "        seed = int(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True # type: ignore\n",
    "    torch.backends.cudnn.benchmark = False # type: ignore\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def tqdm_joblib(tqdm_object):\n",
    "    def tqdm_print_progress(self):\n",
    "        if self.n_completed_tasks > tqdm_object.n:\n",
    "            n_completed = self.n_completed_tasks - tqdm_object.n\n",
    "            tqdm_object.update(n=n_completed)\n",
    "    \n",
    "    original_print_progress = joblib.parallel.Parallel.print_progress\n",
    "    joblib.parallel.Parallel.print_progress = tqdm_print_progress\n",
    "    \n",
    "    try:\n",
    "        yield tqdm_object\n",
    "    finally:\n",
    "        joblib.parallel.Parallel.print_progress = original_print_progress\n",
    "        tqdm_object.close()\n",
    "\n",
    "class SliceSampler(MCMCSampler):\n",
    "    def __init__(self, x, lp_f, max_width=float(\"inf\"), init_width: Union[float, np.ndarray] = 0.05, thin=None, tuning: int = 50, verbose: bool = False,):\n",
    "        MCMCSampler.__init__(self, x, lp_f, thin, verbose=verbose)\n",
    "        self.max_width = max_width\n",
    "        self.init_width = init_width\n",
    "        self.width = None\n",
    "        self.tuning = tuning\n",
    "        \n",
    "    def _tune_bracket_width(self, rng):\n",
    "        order = list(range(self.n_dims))\n",
    "        x = self.x.copy()\n",
    "\n",
    "        self.width = np.full(self.n_dims, self.init_width)\n",
    "\n",
    "        tbar = trange(self.tuning, miniters=2, disable=not self.verbose)\n",
    "        tbar.set_description(\"Tuning bracket width...\")\n",
    "        for n in tbar:\n",
    "            # for n in range(int(self.tuning)):\n",
    "            rng.shuffle(order)\n",
    "            for i in range(self.n_dims):\n",
    "                x[i], wi = self._sample_from_conditional(i, x[i], rng)\n",
    "                self.width[i] += (wi - self.width[i]) / (n + 1)\n",
    "\n",
    "    def _sample_from_conditional(self, i: int, cxi, rng):\n",
    "        assert self.width is not None, \"Chain not initialized.\"\n",
    "\n",
    "        # conditional log prob\n",
    "        Li = lambda t: self.lp_f(np.concatenate([self.x[:i], [t], self.x[i + 1 :]]))\n",
    "        wi = self.width[i]\n",
    "\n",
    "        # sample a slice uniformly\n",
    "        logu = Li(cxi) + np.log(1.0 - rng.rand())\n",
    "\n",
    "        # position the bracket randomly around the current sample\n",
    "        lx = cxi - wi * rng.rand()\n",
    "        ux = lx + wi\n",
    "        \n",
    "        # find lower bracket end\n",
    "        while Li(lx) >= logu and cxi - lx < self.max_width:\n",
    "            lx -= wi\n",
    "\n",
    "        # find upper bracket end\n",
    "        while Li(ux) >= logu and ux - cxi < self.max_width:\n",
    "            ux += wi\n",
    "\n",
    "        # sample uniformly from bracket\n",
    "        xi = (ux - lx) * rng.rand() + lx\n",
    "\n",
    "        # if outside slice, reject sample and shrink bracket\n",
    "        while Li(xi) < logu:\n",
    "            if xi < cxi:\n",
    "                lx = xi\n",
    "            else:\n",
    "                ux = xi\n",
    "            xi = (ux - lx) * rng.rand() + lx\n",
    "       \n",
    "        return xi, ux - lx\n",
    "      \n",
    "def run_fun(SliceSamplerSerial, num_samples, inits, seed, log_prob_fn: Callable, thin: Optional[int] = None, tuning: int = 50, verbose: bool = True, init_width: Union[float, np.ndarray] = 0.01,\n",
    "            max_width: float = float(\"inf\"), num_workers: int = 1, rng=np.random, show_info: bool = False, logger=sys.stdout) -> np.ndarray:\n",
    "    np.random.seed(seed)\n",
    "    posterior_sampler = SliceSampler(inits, lp_f=log_prob_fn, max_width=max_width, init_width=init_width, thin=thin, tuning=tuning, verbose=num_workers == 1 and verbose,)\n",
    "    \n",
    "    assert num_samples >= 0, \"number of samples can't be negative\"\n",
    "\n",
    "    order = list(range(posterior_sampler.n_dims))\n",
    "    L_trace = []\n",
    "    samples = np.empty([int(num_samples), int(posterior_sampler.n_dims)])\n",
    "    logger = open(os.devnull, \"w\") if logger is None else logger\n",
    "\n",
    "    if posterior_sampler.width is None:\n",
    "        # logger.write('tuning bracket width...\\n')\n",
    "        posterior_sampler._tune_bracket_width(rng)\n",
    "\n",
    "    tbar = trange(int(num_samples), miniters=10, disable=not posterior_sampler.verbose)\n",
    "    tbar.set_description(\"Generating samples\")\n",
    "    for n in tbar:\n",
    "        # for n in range(int(n_samples)):\n",
    "        for _ in range(posterior_sampler.thin):\n",
    "            rng.shuffle(order)\n",
    "\n",
    "            for i in order:\n",
    "                posterior_sampler.x[i], _ = posterior_sampler._sample_from_conditional(i, posterior_sampler.x[i], rng)\n",
    "\n",
    "        samples[n] = posterior_sampler.x.copy()\n",
    "\n",
    "        posterior_sampler.L = posterior_sampler.lp_f(posterior_sampler.x)\n",
    "        # logger.write('sample = {0}, log prob = {1:.2}\\n'.format(n+1, self.L))\n",
    "\n",
    "        if show_info:\n",
    "            L_trace.append(posterior_sampler.L)\n",
    "\n",
    "    # show trace plot\n",
    "    if show_info:\n",
    "        fig, ax = plt.subplots(1, 1)\n",
    "        ax.plot(L_trace)\n",
    "        ax.set_ylabel(\"log probability\")\n",
    "        ax.set_xlabel(\"samples\")\n",
    "        plt.show(block=False)\n",
    "\n",
    "    return samples\n",
    "\n",
    "def run(SliceSamplerSerial, log_prob_fn: Callable, num_samples: int, init_params: np.ndarray, num_chains: int = 1, thin: Optional[int] = None, verbose: bool = True, num_workers: int = 1,) -> np.ndarray:\n",
    "    num_chains , dim_samples = init_params.shape\n",
    "    # Generate seeds for workers from current random state.\n",
    "    seeds = torch.randint(high=1_000_000, size=(num_chains,))\n",
    "    for seed in seeds:\n",
    "        seed_all_backends(seed)\n",
    "    with tqdm_joblib(tqdm(range(num_chains), disable=not verbose, desc=f\"\"\"Running {num_chains} MCMC chains with {num_workers} worker{\"s\" if num_workers>1 else \"\"}.\"\"\", total=num_chains,)):\n",
    "        all_samples = Parallel(n_jobs=num_workers)(delayed(run_fun)(SliceSamplerSerial, num_samples, initial_params_batch, seed, log_prob_fn)for initial_params_batch, seed in zip(init_params, seeds))\n",
    "    samples = np.stack(all_samples).astype(np.float32)\n",
    "    samples = samples.reshape(num_chains, -1, dim_samples)  # chains, samples, dim\n",
    "    samples = samples[:, :: thin, :]  # thin chains\n",
    "\n",
    "    # save samples\n",
    "    return samples\n",
    "\n",
    "class SliceSamplerSerial:\n",
    "    def __init__(self, log_prob_fn: Callable, init_params: np.ndarray, num_chains: int = 1, thin: Optional[int] = None, tuning: int = 50, verbose: bool = True, init_width: Union[float, np.ndarray] = 0.01, max_width: float = float(\"inf\"), num_workers: int = 1,):\n",
    "        self._log_prob_fn = log_prob_fn\n",
    "        self.x = init_params\n",
    "        self.num_chains = num_chains\n",
    "        self.thin = thin\n",
    "        self.tuning = tuning\n",
    "        self.verbose = verbose\n",
    "        self.init_width = init_width\n",
    "        self.max_width = max_width\n",
    "        self.n_dims = self.x.size\n",
    "        self.num_workers = num_workers\n",
    "        self._samples = None\n",
    "\n",
    "    def get_samples(self, num_samples: Optional[int] = None, group_by_chain: bool = True) -> np.ndarray:\n",
    "        if self._samples is None:\n",
    "            raise ValueError(\"No samples found from MCMC run.\")\n",
    "        # if not grouped by chain, flatten samples into (all_samples, dim_params)\n",
    "        if not group_by_chain:\n",
    "            samples = self._samples.reshape(-1, self._samples.shape[2])\n",
    "        else:\n",
    "            samples = self._samples\n",
    "\n",
    "        # if not specified return all samples\n",
    "        if num_samples is None:\n",
    "            return samples\n",
    "        # otherwise return last num_samples (for each chain when grouped).\n",
    "        elif group_by_chain:\n",
    "            return samples[:, -num_samples:, :]\n",
    "        else:\n",
    "            return samples[-num_samples:, :]\n",
    "\n",
    "##############################################################################################################################\n",
    "        \n",
    "def _maybe_use_dict_entry(default: Any, key: str, dict_to_check: Dict) -> Any:\n",
    "    attribute = default if key not in dict_to_check.keys() else dict_to_check[key]\n",
    "    return attribute\n",
    "\n",
    "def _get_initial_params(proposal, init_strategy: str, num_chains: int, num_workers: int, show_progress_bars: bool, **kwargs,) -> Tensor: \n",
    "    # Build init function\n",
    "    init_fn = proposal._build_mcmc_init_fn(proposal.proposal, proposal.potential_fn, transform=proposal.theta_transform, init_strategy=init_strategy, **kwargs,)\n",
    "\n",
    "    # Parallelize inits for resampling only.\n",
    "    if num_workers > 1 and (init_strategy == \"resample\" or init_strategy == \"sir\"):\n",
    "        def seeded_init_fn(seed):\n",
    "            torch.manual_seed(seed)\n",
    "            return init_fn()\n",
    "\n",
    "        seeds = torch.randint(high=10_000_000, size=(num_chains,))\n",
    "\n",
    "        # Generate initial params parallelized over num_workers.\n",
    "        with tqdm_joblib(tqdm(range(num_chains), disable=not show_progress_bars, desc=f\"\"\"Generating {num_chains} MCMC inits with {num_workers} workers.\"\"\", total=num_chains,)):\n",
    "            initial_params = torch.cat(Parallel(n_jobs=num_workers)(delayed(seeded_init_fn)(seed) for seed in seeds))\n",
    "    else:\n",
    "        initial_params = torch.cat([init_fn() for _ in range(num_chains)])\n",
    "    return initial_params\n",
    "    \n",
    "def _slice_np_mcmc(proposal, num_samples: int, potential_function: Callable, initial_params: Tensor, thin: int, warmup_steps: int, vectorized: bool = False, num_workers: int = 1, init_width: Union[float, ndarray] = 0.01, show_progress_bars: bool = True,) -> Tensor:\n",
    "    num_chains, dim_samples = initial_params.shape\n",
    "        \n",
    "    if not vectorized:\n",
    "        SliceSamplerMultiChain = SliceSamplerSerial\n",
    "    else:\n",
    "        SliceSamplerMultiChain = SliceSamplerVectorized\n",
    "\n",
    "    posterior_sampler = SliceSamplerMultiChain(init_params=tensor2numpy(initial_params), log_prob_fn=potential_function, num_chains=num_chains, thin=thin, verbose=show_progress_bars, num_workers=num_workers, init_width=init_width,)\n",
    "    warmup_ = warmup_steps * thin\n",
    "    num_samples_ = ceil((num_samples * thin) / num_chains)\n",
    "    # Run mcmc including warmup\n",
    "    samples = run(posterior_sampler, log_prob_fn=potential_function, num_samples = (warmup_ + num_samples_), init_params = tensor2numpy(initial_params))\n",
    "    samples = samples[:, warmup_steps:, :]  # discard warmup steps\n",
    "    samples = torch.from_numpy(samples)  # chains x samples x dim\n",
    "\n",
    "    # Save posterior sampler.\n",
    "    proposal._posterior_sampler = posterior_sampler\n",
    "\n",
    "    # Save sample as potential next init (if init_strategy == 'latest_sample').\n",
    "    proposal._mcmc_init_params = samples[:, -1, :].reshape(num_chains, dim_samples)\n",
    "\n",
    "    # Collect samples from all chains.\n",
    "    samples = samples.reshape(-1, dim_samples)[:num_samples, :]\n",
    "    assert samples.shape[0] == num_samples\n",
    "    return samples.type(torch.float32).to(proposal._device)\n",
    "\n",
    "def sample_my_fun(proposal, sample_shape: Shape = torch.Size(), x: Optional[Tensor] = None, method: Optional[str] = None, thin: Optional[int] = None, warmup_steps: Optional[int] = None, num_chains: Optional[int] = None, init_strategy: Optional[str] = None, init_strategy_parameters: Optional[Dict[str, Any]] = None,\n",
    "                   init_strategy_num_candidates: Optional[int] = None, mcmc_parameters: Dict = {}, mcmc_method: Optional[str] = None, sample_with: Optional[str] = None, num_workers: Optional[int] = None, show_progress_bars: bool = True,) -> Tensor:\n",
    "    \n",
    "    proposal.potential_fn.set_x(proposal._x_else_default_x(x))\n",
    "\n",
    "    # Replace arguments that were not passed with their default.\n",
    "    method = proposal.method if method is None else method\n",
    "    thin = proposal.thin if thin is None else thin\n",
    "    warmup_steps = proposal.warmup_steps if warmup_steps is None else warmup_steps\n",
    "    num_chains = proposal.num_chains if num_chains is None else num_chains\n",
    "    init_strategy = proposal.init_strategy if init_strategy is None else init_strategy\n",
    "    num_workers = proposal.num_workers if num_workers is None else num_workers\n",
    "    init_strategy_parameters = (proposal.init_strategy_parameters if init_strategy_parameters is None else init_strategy_parameters)\n",
    "\n",
    "    if init_strategy_num_candidates is not None:\n",
    "        warn(\"\"\"Passing `init_strategy_num_candidates` is deprecated as of sbi v0.19.0. Instead, use e.g.,`init_strategy_parameters={\"num_candidate_samples\": 1000}`\"\"\")\n",
    "        proposal.init_strategy_parameters[\"num_candidate_samples\"] = (init_strategy_num_candidates)\n",
    "    if sample_with is not None:\n",
    "        raise ValueError(f\"You set `sample_with={sample_with}`. As of sbi v0.18.0, setting `sample_with` is no longer supported. You have to rerun `.build_posterior(sample_with={sample_with}).`\")\n",
    "    if mcmc_method is not None:\n",
    "        warn(\"You passed `mcmc_method` to `.sample()`. As of sbi v0.18.0, this is deprecated and will be removed in a future release. Use `method` instead of `mcmc_method`.\")\n",
    "        method = mcmc_method\n",
    "    if mcmc_parameters:\n",
    "        warn(\"You passed `mcmc_parameters` to `.sample()`. As of sbi v0.18.0, this is deprecated and will be removed in a future release. Instead, pass the variable to `.sample()` directly, e.g. `posterior.sample((1,), num_chains=5)`.\")\n",
    "    # The following lines are only for backwards compatibility with sbi v0.17.2 or older.\n",
    "    m_p = mcmc_parameters  # define to shorten the variable name\n",
    "    method = _maybe_use_dict_entry(method, \"mcmc_method\", m_p)\n",
    "    thin = _maybe_use_dict_entry(thin, \"thin\", m_p)\n",
    "    warmup_steps = _maybe_use_dict_entry(warmup_steps, \"warmup_steps\", m_p)\n",
    "    num_chains = _maybe_use_dict_entry(num_chains, \"num_chains\", m_p)\n",
    "    init_strategy = _maybe_use_dict_entry(init_strategy, \"init_strategy\", m_p)\n",
    "    proposal.potential_ = proposal._prepare_potential(method)  # type: ignore\n",
    "\n",
    "    initial_params = _get_initial_params(proposal, init_strategy, num_chains, num_workers, show_progress_bars, **init_strategy_parameters,)\n",
    "    num_samples = torch.Size(sample_shape).numel()\n",
    "\n",
    "    track_gradients = method in (\"hmc\", \"nuts\")\n",
    "    with torch.set_grad_enabled(track_gradients):\n",
    "        if method in (\"slice_np\", \"slice_np_vectorized\"):\n",
    "            transformed_samples = _slice_np_mcmc(proposal, num_samples=num_samples, potential_function=proposal.potential_, initial_params=initial_params, thin=thin, warmup_steps=warmup_steps, vectorized=(method == \"slice_np_vectorized\"), num_workers=num_workers, show_progress_bars=show_progress_bars,)\n",
    "        elif method in (\"hmc\", \"nuts\", \"slice\"):\n",
    "            transformed_samples = _pyro_mcmc(proposal, num_samples=num_samples, potential_function=proposal.potential_, initial_params=initial_params, mcmc_method=method, thin=thin, warmup_steps=warmup_steps, num_chains=num_chains, show_progress_bars=show_progress_bars,)\n",
    "        else:\n",
    "            raise NameError\n",
    "\n",
    "    samples = proposal.theta_transform.inv(transformed_samples)\n",
    "\n",
    "    return samples.reshape((*sample_shape, -1))  # type: ignore\n",
    "\n",
    "#######################################################################################################################################\n",
    "\n",
    "def simulator_seeded(simulator: Callable, theta: Tensor, seed: int) -> Tensor:\n",
    "    import torch\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    with torch.random.fork_rng(devices=[]):\n",
    "        torch.manual_seed(seed)\n",
    "        return simulator(theta)\n",
    "\n",
    "def simulate_in_batches(simulator: Callable, theta: Tensor, sim_batch_size: int = 1, num_workers: int = 1 , seed: Optional[int] = None, show_progress_bars: bool = True, ) -> Tensor:\n",
    "    num_sims, *_ = theta.shape\n",
    "    seed_all_backends(seed)\n",
    "    if num_sims == 0:\n",
    "        x = torch.tensor([])\n",
    "    elif sim_batch_size is not None and sim_batch_size < num_sims:\n",
    "        batches = split(theta, sim_batch_size, dim=0)\n",
    "        \n",
    "        if num_workers != 1:\n",
    "            batch_seeds = randint(high=1_000_000, size=(len(batches),))\n",
    "            with tqdm_joblib(tqdm(batches, disable=not show_progress_bars, total = len(batches), desc=f\"Running {num_sims} simulations in {len(batches)} batches ({num_workers} cores)\",)) as _:\n",
    "                simulation_outputs = Parallel(n_jobs=num_workers)(delayed(simulator_seeded)(simulator, batch, batch_seed) for batch, batch_seed in zip(batches, batch_seeds))\n",
    "        else:\n",
    "            pbar = tqdm(total=num_sims, disable=not show_progress_bars, desc=f\"Running {num_sims} simulations.\", )\n",
    "            with pbar:\n",
    "                simulation_outputs = []\n",
    "                for batch in batches:\n",
    "                    simulation_outputs.append(simulator_seeded(simulator, batch, seed))\n",
    "                    pbar.update(sim_batch_size)\n",
    "        x = cat(simulation_outputs, dim=0)\n",
    "    else:\n",
    "        x = simulator(theta)\n",
    "    return x\n",
    "\n",
    "def simulate_for_sbi(round_idx: int, simulator: Callable, proposal: Any, num_simulations: int, num_workers: int = 1, simulation_batch_size: int = 1, seed: Optional[int] = None, show_progress_bar: bool = True)-> Tuple[Tensor, Tensor]:\n",
    "    if round_idx == 0:\n",
    "        theta = proposal.sample((num_simulations,))\n",
    "    else:\n",
    "        theta = sample_my_fun(proposal, (num_simulations,), num_workers = num_workers, num_chains = 4) # because only in first round proposal is boxuniform, then it is mcmcposterior object\n",
    "    \n",
    "    x = simulate_in_batches(simulator=simulator, theta=theta, sim_batch_size=simulation_batch_size, num_workers=num_workers, seed=seed, show_progress_bars=show_progress_bar)\n",
    "    \n",
    "    return theta, x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.gru = nn.GRU(input_size, hidden_size, batch_first=True) #batch_size of 100\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "                                                       #The middle value needs to be the length, in this case 1000, or input.size(0) (try with true_data)\n",
    "                                                        #1 is the number of layers\n",
    "                                                        #Actually prepare for sbi adds a batch_size, so x.shape is (1, 1000, 6)\n",
    "    def forward(self, x):\n",
    "        h = torch.zeros(1, x.size(0), self.hidden_size)\n",
    "        gru_out, hn = self.gru(\n",
    "            x, h)\n",
    "        output = self.linear(gru_out[:,-1, :])\n",
    "        return output\n",
    "\n",
    "# Example usage\n",
    "input_size = 6 #Needs to be the same as input.size(-1)\n",
    "output_size = 25\n",
    "hidden_size = 100\n",
    "embedding_net = RNN(input_size, hidden_size, output_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "For unbatched 2-D input, hx should also be 2-D but got 3-D tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m gru \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mGRU(\u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m100\u001b[39m, batch_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m h \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m gru_out, hn \u001b[38;5;241m=\u001b[39m \u001b[43mgru\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrue_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m linear \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(hidden_size, output_size)\n\u001b[1;32m      5\u001b[0m out \u001b[38;5;241m=\u001b[39m linear(gru_out[:,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :])\n",
      "File \u001b[0;32m~/Desktop/SBI/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/SBI/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/SBI/.conda/lib/python3.11/site-packages/torch/nn/modules/rnn.py:1080\u001b[0m, in \u001b[0;36mGRU.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1078\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1079\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m hx\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m-> 1080\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1081\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor unbatched 2-D input, hx should also be 2-D but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhx\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-D tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1082\u001b[0m         hx \u001b[38;5;241m=\u001b[39m hx\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   1083\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: For unbatched 2-D input, hx should also be 2-D but got 3-D tensor"
     ]
    }
   ],
   "source": [
    "gru = nn.GRU(6, 100, batch_first=True)\n",
    "h = torch.zeros(1, 3, 100)\n",
    "gru_out, hn = gru(true_data, h)\n",
    "linear = nn.Linear(hidden_size, output_size)\n",
    "out = linear(gru_out[:,-1, :])\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### paralellise #####\n",
    "\n",
    "#Parallelise it\n",
    "# PART 1: Edited code from original sbi repos. Functions edited: simulate_for_sbi, and all the functions it contains.\n",
    "#Main changes: defined simulator_seeded globally rather than within simulate_in_batches function, and re-imported torch within simulator_seeded \n",
    "#NO changes need to be made in this file\n",
    "\n",
    "# PART 2: Essentially the unparallelised code with 2 extra arguments in the simulate_for_sbi line\n",
    "\n",
    "##################################### PART 1 #########################################\n",
    "import joblib\n",
    "import contextlib\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from torch import Tensor, split, randint, cat\n",
    "from typing import Any, Callable, Optional, Tuple, Union\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import sbi\n",
    "from scipy.integrate import odeint\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sbi.inference import SNLE, prepare_for_sbi\n",
    "# No longer importing simulate_for_sbi from the package, we use the one defined above\n",
    "from sbi import utils as utils\n",
    "from sbi import analysis as analysis\n",
    "\n",
    "def seed_all_backends(seed: Optional[Union[int, Tensor]] = None) -> None:\n",
    "    if seed is None:\n",
    "        seed = int(torch.randint(1_000_000, size=(1,)))\n",
    "    else:\n",
    "        # Cast Tensor to int (required by math.random since Python 3.11)\n",
    "        seed = int(seed)\n",
    "\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True # type: ignore\n",
    "    torch.backends.cudnn.benchmark = False # type: ignore\n",
    "\n",
    "def simulator_seeded(simulator: Callable, theta: Tensor, seed: int) -> Tensor:\n",
    "    import torch\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    with torch.random.fork_rng(devices=[]):\n",
    "        torch.manual_seed(seed)\n",
    "        return simulator(theta)\n",
    "\n",
    "def simulate_in_batches(simulator: Callable, theta: Tensor, sim_batch_size: int = 1, num_workers: int = 1,\n",
    "                        seed: Optional[int] = None, show_progress_bars: bool = True, ) -> Tensor:\n",
    "\n",
    "    num_sims, *_ = theta.shape\n",
    "    seed_all_backends(seed)\n",
    "\n",
    "    if num_sims == 0:\n",
    "        x = torch.tensor([])\n",
    "    elif sim_batch_size is not None and sim_batch_size < num_sims:\n",
    "        batches = split(theta, sim_batch_size, dim=0)\n",
    "\n",
    "        if num_workers != 1:\n",
    "            batch_seeds = randint(high=1_000_000, size=(len(batches),))\n",
    "\n",
    "            with tqdm_joblib(\n",
    "                tqdm(batches, disable=not show_progress_bars,\n",
    "                     desc=f\"Running {num_sims} simulations in {len(batches)} batches.\", total=len(batches),)) as _:\n",
    "                simulation_outputs = Parallel(n_jobs=num_workers)(delayed(simulator_seeded)(simulator, batch, batch_seed)\n",
    "                    for batch, batch_seed in zip(batches, batch_seeds))\n",
    "        else:\n",
    "            pbar = tqdm(total=num_sims, disable=not show_progress_bars, desc=f\"Running {num_sims} simulations.\", )\n",
    "\n",
    "            with pbar:\n",
    "                simulation_outputs = []\n",
    "                for batch in batches:\n",
    "                    simulation_outputs.append(simulator_seeded(simulator, batch, seed))\n",
    "                    pbar.update(sim_batch_size)\n",
    "\n",
    "        x = cat(simulation_outputs, dim=0)\n",
    "    else:\n",
    "        x = simulator(theta)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def tqdm_joblib(tqdm_object):\n",
    "    def tqdm_print_progress(self):\n",
    "        if self.n_completed_tasks > tqdm_object.n:\n",
    "            n_completed = self.n_completed_tasks - tqdm_object.n\n",
    "            tqdm_object.update(n=n_completed)\n",
    "\n",
    "    original_print_progress = joblib.parallel.Parallel.print_progress\n",
    "    joblib.parallel.Parallel.print_progress = tqdm_print_progress\n",
    "\n",
    "    try:\n",
    "        yield tqdm_object\n",
    "    finally:\n",
    "        joblib.parallel.Parallel.print_progress = original_print_progress\n",
    "        tqdm_object.close()\n",
    "\n",
    "def simulate_for_sbi(simulator: Callable, proposal: Any, num_simulations: int, num_workers: int = 1,\n",
    "                     simulation_batch_size: int = 1, seed: Optional[int] = None,\n",
    "                     show_progress_bar: bool = True, ) -> Tuple[Tensor, Tensor]:\n",
    "\n",
    "    theta = proposal.sample((num_simulations,))\n",
    "\n",
    "    x = simulate_in_batches(simulator=simulator, theta=theta, sim_batch_size=simulation_batch_size,\n",
    "                            num_workers=num_workers, seed=seed, show_progress_bars=show_progress_bar,)\n",
    "\n",
    "    return theta, x\n",
    "\n",
    "######################################################################################################\n",
    "\n",
    "# To parallelise, set number of CPUs to be used. Note: parallelise anything that has num_rounds>2 and/or num_simulations>50\n",
    "# to see total available CPUs: print(os.cpu_count())\n",
    "\n",
    "CPUs_to_use = 8\n",
    "\n",
    "total_CPUs = os.cpu_count()\n",
    "num_workers = CPUs_to_use - total_CPUs -1\n",
    "# num_workers = -1 uses all cpus\n",
    "# num_workers = -2 uses all cpus but one etc https://joblib.readthedocs.io/en/latest/generated/joblib.Parallel.html\n",
    "if CPUs_to_use > total_CPUs:\n",
    "    raise ValueError(f\"Cannot use more CPUs than are available. Available CPUs: {total_CPUs}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## snpec gpu ######\n",
    "\n",
    "# This file is part of sbi, a toolkit for simulation-based inference. sbi is licensed\n",
    "# under the Affero General Public License v3, see <https://www.gnu.org/licenses/>.\n",
    "\n",
    "\n",
    "from typing import Callable, Dict, Optional, Union\n",
    "\n",
    "import torch\n",
    "from pyknos.mdn.mdn import MultivariateGaussianMDN as mdn\n",
    "from pyknos.nflows.transforms import CompositeTransform\n",
    "from torch import Tensor, eye, nn, ones\n",
    "from torch.distributions import Distribution, MultivariateNormal, Uniform\n",
    "\n",
    "from sbi import utils as utils\n",
    "from sbi.inference.posteriors.direct_posterior import DirectPosterior\n",
    "from sbi.inference.snpe.snpe_base import PosteriorEstimator\n",
    "from sbi.types import TensorboardSummaryWriter\n",
    "from sbi.utils import (\n",
    "    batched_mixture_mv,\n",
    "    batched_mixture_vmv,\n",
    "    check_dist_class,\n",
    "    clamp_and_warn,\n",
    "    del_entries,\n",
    "    repeat_rows,\n",
    ")\n",
    "\n",
    "\n",
    "class SNPE_C(PosteriorEstimator):\n",
    "    def __init__(\n",
    "        self,\n",
    "        prior: Optional[Distribution] = None,\n",
    "        density_estimator: Union[str, Callable] = \"maf\",\n",
    "        device: str = \"gpu\",\n",
    "        logging_level: Union[int, str] = \"WARNING\",\n",
    "        summary_writer: Optional[TensorboardSummaryWriter] = None,\n",
    "        show_progress_bars: bool = True,\n",
    "    ):\n",
    "        r\"\"\"SNPE-C / APT [1].\n",
    "\n",
    "        [1] _Automatic Posterior Transformation for Likelihood-free Inference_,\n",
    "            Greenberg et al., ICML 2019, https://arxiv.org/abs/1905.07488.\n",
    "\n",
    "        This class implements two loss variants of SNPE-C: the non-atomic and the atomic\n",
    "        version. The atomic loss of SNPE-C can be used for any density estimator,\n",
    "        i.e. also for normalizing flows. However, it suffers from leakage issues. On\n",
    "        the other hand, the non-atomic loss can only be used only if the proposal\n",
    "        distribution is a mixture of Gaussians, the density estimator is a mixture of\n",
    "        Gaussians, and the prior is either Gaussian or Uniform. It does not suffer from\n",
    "        leakage issues. At the beginning of each round, we print whether the non-atomic\n",
    "        or the atomic version is used.\n",
    "\n",
    "        In this codebase, we will automatically switch to the non-atomic loss if the\n",
    "        following criteria are fulfilled:<br/>\n",
    "        - proposal is a `DirectPosterior` with density_estimator `mdn`, as built\n",
    "            with `utils.sbi.posterior_nn()`.<br/>\n",
    "        - the density estimator is a `mdn`, as built with\n",
    "            `utils.sbi.posterior_nn()`.<br/>\n",
    "        - `isinstance(prior, MultivariateNormal)` (from `torch.distributions`) or\n",
    "            `isinstance(prior, sbi.utils.BoxUniform)`\n",
    "\n",
    "        Note that custom implementations of any of these densities (or estimators) will\n",
    "        not trigger the non-atomic loss, and the algorithm will fall back onto using\n",
    "        the atomic loss.\n",
    "\n",
    "        Args:\n",
    "            prior: A probability distribution that expresses prior knowledge about the\n",
    "                parameters, e.g. which ranges are meaningful for them.\n",
    "            density_estimator: If it is a string, use a pre-configured network of the\n",
    "                provided type (one of nsf, maf, mdn, made). Alternatively, a function\n",
    "                that builds a custom neural network can be provided. The function will\n",
    "                be called with the first batch of simulations (theta, x), which can\n",
    "                thus be used for shape inference and potentially for z-scoring. It\n",
    "                needs to return a PyTorch `nn.Module` implementing the density\n",
    "                estimator. The density estimator needs to provide the methods\n",
    "                `.log_prob` and `.sample()`.\n",
    "            device: Training device, e.g., \"cpu\", \"cuda\" or \"cuda:{0, 1, ...}\".\n",
    "            logging_level: Minimum severity of messages to log. One of the strings\n",
    "                INFO, WARNING, DEBUG, ERROR and CRITICAL.\n",
    "            summary_writer: A tensorboard `SummaryWriter` to control, among others, log\n",
    "                file location (default is `<current working directory>/logs`.)\n",
    "            show_progress_bars: Whether to show a progressbar during training.\n",
    "        \"\"\"\n",
    "\n",
    "        kwargs = del_entries(locals(), entries=(\"self\", \"__class__\"))\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def train(\n",
    "        self,\n",
    "        num_atoms: int = 10,\n",
    "        training_batch_size: int = 50,\n",
    "        learning_rate: float = 5e-4,\n",
    "        validation_fraction: float = 0.1,\n",
    "        stop_after_epochs: int = 20,\n",
    "        max_num_epochs: int = 2**31 - 1,\n",
    "        clip_max_norm: Optional[float] = 5.0,\n",
    "        calibration_kernel: Optional[Callable] = None,\n",
    "        resume_training: bool = False,\n",
    "        force_first_round_loss: bool = False,\n",
    "        discard_prior_samples: bool = False,\n",
    "        use_combined_loss: bool = False,\n",
    "        retrain_from_scratch: bool = False,\n",
    "        show_train_summary: bool = False,\n",
    "        dataloader_kwargs: Optional[Dict] = None,\n",
    "    ) -> nn.Module:\n",
    "        r\"\"\"Return density estimator that approximates the distribution $p(\\theta|x)$.\n",
    "\n",
    "        Args:\n",
    "            num_atoms: Number of atoms to use for classification.\n",
    "            training_batch_size: Training batch size.\n",
    "            learning_rate: Learning rate for Adam optimizer.\n",
    "            validation_fraction: The fraction of data to use for validation.\n",
    "            stop_after_epochs: The number of epochs to wait for improvement on the\n",
    "                validation set before terminating training.\n",
    "            max_num_epochs: Maximum number of epochs to run. If reached, we stop\n",
    "                training even when the validation loss is still decreasing. Otherwise,\n",
    "                we train until validation loss increases (see also `stop_after_epochs`).\n",
    "            clip_max_norm: Value at which to clip the total gradient norm in order to\n",
    "                prevent exploding gradients. Use None for no clipping.\n",
    "            calibration_kernel: A function to calibrate the loss with respect to the\n",
    "                simulations `x`. See Lueckmann, Gon√ßalves et al., NeurIPS 2017.\n",
    "            resume_training: Can be used in case training time is limited, e.g. on a\n",
    "                cluster. If `True`, the split between train and validation set, the\n",
    "                optimizer, the number of epochs, and the best validation log-prob will\n",
    "                be restored from the last time `.train()` was called.\n",
    "            force_first_round_loss: If `True`, train with maximum likelihood,\n",
    "                i.e., potentially ignoring the correction for using a proposal\n",
    "                distribution different from the prior.\n",
    "            discard_prior_samples: Whether to discard samples simulated in round 1, i.e.\n",
    "                from the prior. Training may be sped up by ignoring such less targeted\n",
    "                samples.\n",
    "            use_combined_loss: Whether to train the neural net also on prior samples\n",
    "                using maximum likelihood in addition to training it on all samples using\n",
    "                atomic loss. The extra MLE loss helps prevent density leaking with\n",
    "                bounded priors.\n",
    "            retrain_from_scratch: Whether to retrain the conditional density\n",
    "                estimator for the posterior from scratch each round.\n",
    "            show_train_summary: Whether to print the number of epochs and validation\n",
    "                loss and leakage after the training.\n",
    "            dataloader_kwargs: Additional or updated kwargs to be passed to the training\n",
    "                and validation dataloaders (like, e.g., a collate_fn)\n",
    "\n",
    "        Returns:\n",
    "            Density estimator that approximates the distribution $p(\\theta|x)$.\n",
    "        \"\"\"\n",
    "\n",
    "        # WARNING: sneaky trick ahead. We proxy the parent's `train` here,\n",
    "        # requiring the signature to have `num_atoms`, save it for use below, and\n",
    "        # continue. It's sneaky because we are using the object (self) as a namespace\n",
    "        # to pass arguments between functions, and that's implicit state management.\n",
    "        self._num_atoms = num_atoms\n",
    "        self._use_combined_loss = use_combined_loss\n",
    "        kwargs = del_entries(\n",
    "            locals(),\n",
    "            entries=(\"self\", \"__class__\", \"num_atoms\", \"use_combined_loss\"),\n",
    "        )\n",
    "\n",
    "        self._round = max(self._data_round_index)\n",
    "\n",
    "        if self._round > 0:\n",
    "            # Set the proposal to the last proposal that was passed by the user. For\n",
    "            # atomic SNPE, it does not matter what the proposal is. For non-atomic\n",
    "            # SNPE, we only use the latest data that was passed, i.e. the one from the\n",
    "            # last proposal.\n",
    "            proposal = self._proposal_roundwise[-1]\n",
    "            self.use_non_atomic_loss = (\n",
    "                isinstance(proposal, DirectPosterior)\n",
    "                and isinstance(proposal.posterior_estimator._distribution, mdn)\n",
    "                and isinstance(self._neural_net._distribution, mdn)\n",
    "                and check_dist_class(\n",
    "                    self._prior, class_to_check=(Uniform, MultivariateNormal)\n",
    "                )[0]\n",
    "            )\n",
    "\n",
    "            algorithm = \"non-atomic\" if self.use_non_atomic_loss else \"atomic\"\n",
    "            print(f\"Using SNPE-C with {algorithm} loss\")\n",
    "\n",
    "            if self.use_non_atomic_loss:\n",
    "                # Take care of z-scoring, pre-compute and store prior terms.\n",
    "                self._set_state_for_mog_proposal()\n",
    "\n",
    "        return super().train(**kwargs)\n",
    "\n",
    "    def _set_state_for_mog_proposal(self) -> None:\n",
    "        \"\"\"Set state variables that are used at each training step of non-atomic SNPE-C.\n",
    "\n",
    "        Three things are computed:\n",
    "        1) Check if z-scoring was requested. To do so, we check if the `_transform`\n",
    "            argument of the net had been a `CompositeTransform`. See pyknos mdn.py.\n",
    "        2) Define a (potentially standardized) prior. It's standardized if z-scoring\n",
    "            had been requested.\n",
    "        3) Compute (Precision * mean) for the prior. This quantity is used at every\n",
    "            training step if the prior is Gaussian.\n",
    "        \"\"\"\n",
    "\n",
    "        self.z_score_theta = isinstance(self._neural_net._transform, CompositeTransform)\n",
    "\n",
    "        self._set_maybe_z_scored_prior()\n",
    "\n",
    "        if isinstance(self._maybe_z_scored_prior, MultivariateNormal):\n",
    "            self.prec_m_prod_prior = torch.mv(\n",
    "                self._maybe_z_scored_prior.precision_matrix,  # type: ignore\n",
    "                self._maybe_z_scored_prior.loc,  # type: ignore\n",
    "            )\n",
    "\n",
    "    def _set_maybe_z_scored_prior(self) -> None:\n",
    "        r\"\"\"Compute and store potentially standardized prior (if z-scoring was done).\n",
    "\n",
    "        The proposal posterior is:\n",
    "        $pp(\\theta|x) = 1/Z * q(\\theta|x) * prop(\\theta) / p(\\theta)$\n",
    "\n",
    "        Let's denote z-scored theta by `a`: a = (theta - mean) / std\n",
    "        Then pp'(a|x) = 1/Z_2 * q'(a|x) * prop'(a) / p'(a)$\n",
    "\n",
    "        The ' indicates that the evaluation occurs in standardized space. The constant\n",
    "        scaling factor has been absorbed into Z_2.\n",
    "        From the above equation, we see that we need to evaluate the prior **in\n",
    "        standardized space**. We build the standardized prior in this function.\n",
    "\n",
    "        The standardize transform that is applied to the samples theta does not use\n",
    "        the exact prior mean and std (due to implementation issues). Hence, the z-scored\n",
    "        prior will not be exactly have mean=0 and std=1.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.z_score_theta:\n",
    "            scale = self._neural_net._transform._transforms[0]._scale\n",
    "            shift = self._neural_net._transform._transforms[0]._shift\n",
    "\n",
    "            # Following the definintion of the linear transform in\n",
    "            # `standardizing_transform` in `sbiutils.py`:\n",
    "            # shift=-mean / std\n",
    "            # scale=1 / std\n",
    "            # Solving these equations for mean and std:\n",
    "            estim_prior_std = 1 / scale\n",
    "            estim_prior_mean = -shift * estim_prior_std\n",
    "\n",
    "            # Compute the discrepancy of the true prior mean and std and the mean and\n",
    "            # std that was empirically estimated from samples.\n",
    "            # N(theta|m,s) = N((theta-m_e)/s_e|(m-m_e)/s_e, s/s_e)\n",
    "            # Above: m,s are true prior mean and std. m_e,s_e are estimated prior mean\n",
    "            # and std (estimated from samples and used to build standardize transform).\n",
    "            almost_zero_mean = (self._prior.mean - estim_prior_mean) / estim_prior_std\n",
    "            almost_one_std = torch.sqrt(self._prior.variance) / estim_prior_std\n",
    "\n",
    "            if isinstance(self._prior, MultivariateNormal):\n",
    "                self._maybe_z_scored_prior = MultivariateNormal(\n",
    "                    almost_zero_mean, torch.diag(almost_one_std)\n",
    "                )\n",
    "            else:\n",
    "                range_ = torch.sqrt(almost_one_std * 3.0)\n",
    "                self._maybe_z_scored_prior = utils.BoxUniform(\n",
    "                    almost_zero_mean - range_, almost_zero_mean + range_\n",
    "                )\n",
    "        else:\n",
    "            self._maybe_z_scored_prior = self._prior\n",
    "\n",
    "    def _log_prob_proposal_posterior(\n",
    "        self,\n",
    "        theta: Tensor,\n",
    "        x: Tensor,\n",
    "        masks: Tensor,\n",
    "        proposal: DirectPosterior,\n",
    "    ) -> Tensor:\n",
    "        \"\"\"Return the log-probability of the proposal posterior.\n",
    "\n",
    "        If the proposal is a MoG, the density estimator is a MoG, and the prior is\n",
    "        either Gaussian or uniform, we use non-atomic loss. Else, use atomic loss (which\n",
    "        suffers from leakage).\n",
    "\n",
    "        Args:\n",
    "            theta: Batch of parameters Œ∏.\n",
    "            x: Batch of data.\n",
    "            masks: Mask that is True for prior samples in the batch in order to train\n",
    "                them with prior loss.\n",
    "            proposal: Proposal distribution.\n",
    "\n",
    "        Returns: Log-probability of the proposal posterior.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.use_non_atomic_loss:\n",
    "            return self._log_prob_proposal_posterior_mog(theta, x, proposal)\n",
    "        else:\n",
    "            return self._log_prob_proposal_posterior_atomic(theta, x, masks)\n",
    "\n",
    "    def _log_prob_proposal_posterior_atomic(\n",
    "        self, theta: Tensor, x: Tensor, masks: Tensor\n",
    "    ):\n",
    "        \"\"\"Return log probability of the proposal posterior for atomic proposals.\n",
    "\n",
    "        We have two main options when evaluating the proposal posterior.\n",
    "            (1) Generate atoms from the proposal prior.\n",
    "            (2) Generate atoms from a more targeted distribution, such as the most\n",
    "                recent posterior.\n",
    "        If we choose the latter, it is likely beneficial not to do this in the first\n",
    "        round, since we would be sampling from a randomly-initialized neural density\n",
    "        estimator.\n",
    "\n",
    "        Args:\n",
    "            theta: Batch of parameters Œ∏.\n",
    "            x: Batch of data.\n",
    "            masks: Mask that is True for prior samples in the batch in order to train\n",
    "                them with prior loss.\n",
    "\n",
    "        Returns:\n",
    "            Log-probability of the proposal posterior.\n",
    "        \"\"\"\n",
    "\n",
    "        batch_size = theta.shape[0]\n",
    "\n",
    "        num_atoms = int(\n",
    "            clamp_and_warn(\"num_atoms\", self._num_atoms, min_val=2, max_val=batch_size)\n",
    "        )\n",
    "\n",
    "        # Each set of parameter atoms is evaluated using the same x,\n",
    "        # so we repeat rows of the data x, e.g. [1, 2] -> [1, 1, 2, 2]\n",
    "        repeated_x = repeat_rows(x, num_atoms)\n",
    "\n",
    "        # To generate the full set of atoms for a given item in the batch,\n",
    "        # we sample without replacement num_atoms - 1 times from the rest\n",
    "        # of the theta in the batch.\n",
    "        probs = ones(batch_size, batch_size) * (1 - eye(batch_size)) / (batch_size - 1)\n",
    "\n",
    "        choices = torch.multinomial(probs, num_samples=num_atoms - 1, replacement=False)\n",
    "        contrasting_theta = theta[choices]\n",
    "\n",
    "        # We can now create our sets of atoms from the contrasting parameter sets\n",
    "        # we have generated.\n",
    "        atomic_theta = torch.cat((theta[:, None, :], contrasting_theta), dim=1).reshape(\n",
    "            batch_size * num_atoms, -1\n",
    "        )\n",
    "\n",
    "        # Evaluate large batch giving (batch_size * num_atoms) log prob posterior evals.\n",
    "        log_prob_posterior = self._neural_net.log_prob(atomic_theta, repeated_x)\n",
    "        utils.assert_all_finite(log_prob_posterior, \"posterior eval\")\n",
    "        log_prob_posterior = log_prob_posterior.reshape(batch_size, num_atoms)\n",
    "\n",
    "        # Get (batch_size * num_atoms) log prob prior evals.\n",
    "        log_prob_prior = self._prior.log_prob(atomic_theta)\n",
    "        log_prob_prior = log_prob_prior.reshape(batch_size, num_atoms)\n",
    "        utils.assert_all_finite(log_prob_prior, \"prior eval\")\n",
    "\n",
    "        # Compute unnormalized proposal posterior.\n",
    "        unnormalized_log_prob = log_prob_posterior - log_prob_prior\n",
    "\n",
    "        # Normalize proposal posterior across discrete set of atoms.\n",
    "        log_prob_proposal_posterior = unnormalized_log_prob[:, 0] - torch.logsumexp(\n",
    "            unnormalized_log_prob, dim=-1\n",
    "        )\n",
    "        utils.assert_all_finite(log_prob_proposal_posterior, \"proposal posterior eval\")\n",
    "\n",
    "        # XXX This evaluates the posterior on _all_ prior samples\n",
    "        if self._use_combined_loss:\n",
    "            log_prob_posterior_non_atomic = self._neural_net.log_prob(theta, x)\n",
    "            masks = masks.reshape(-1)\n",
    "            log_prob_proposal_posterior = (\n",
    "                masks * log_prob_posterior_non_atomic + log_prob_proposal_posterior\n",
    "            )\n",
    "\n",
    "        return log_prob_proposal_posterior\n",
    "\n",
    "    def _log_prob_proposal_posterior_mog(\n",
    "        self, theta: Tensor, x: Tensor, proposal: DirectPosterior\n",
    "    ) -> Tensor:\n",
    "        \"\"\"Return log-probability of the proposal posterior for MoG proposal.\n",
    "\n",
    "        For MoG proposals and MoG density estimators, this can be done in closed form\n",
    "        and does not require atomic loss (i.e. there will be no leakage issues).\n",
    "\n",
    "        Notation:\n",
    "\n",
    "        m are mean vectors.\n",
    "        prec are precision matrices.\n",
    "        cov are covariance matrices.\n",
    "\n",
    "        _p at the end indicates that it is the proposal.\n",
    "        _d indicates that it is the density estimator.\n",
    "        _pp indicates the proposal posterior.\n",
    "\n",
    "        All tensors will have shapes (batch_dim, num_components, ...)\n",
    "\n",
    "        Args:\n",
    "            theta: Batch of parameters Œ∏.\n",
    "            x: Batch of data.\n",
    "            proposal: Proposal distribution.\n",
    "\n",
    "        Returns:\n",
    "            Log-probability of the proposal posterior.\n",
    "        \"\"\"\n",
    "\n",
    "        # Evaluate the proposal. MDNs do not have functionality to run the embedding_net\n",
    "        # and then get the mixture_components (**without** calling log_prob()). Hence,\n",
    "        # we call them separately here.\n",
    "        encoded_x = proposal.posterior_estimator._embedding_net(proposal.default_x)\n",
    "        dist = (\n",
    "            proposal.posterior_estimator._distribution\n",
    "        )  # defined to avoid ugly black formatting.\n",
    "        logits_p, m_p, prec_p, _, _ = dist.get_mixture_components(encoded_x)\n",
    "        norm_logits_p = logits_p - torch.logsumexp(logits_p, dim=-1, keepdim=True)\n",
    "\n",
    "        # Evaluate the density estimator.\n",
    "        encoded_x = self._neural_net._embedding_net(x)\n",
    "        dist = self._neural_net._distribution  # defined to avoid black formatting.\n",
    "        logits_d, m_d, prec_d, _, _ = dist.get_mixture_components(encoded_x)\n",
    "        norm_logits_d = logits_d - torch.logsumexp(logits_d, dim=-1, keepdim=True)\n",
    "\n",
    "        # z-score theta if it z-scoring had been requested.\n",
    "        theta = self._maybe_z_score_theta(theta)\n",
    "\n",
    "        # Compute the MoG parameters of the proposal posterior.\n",
    "        (\n",
    "            logits_pp,\n",
    "            m_pp,\n",
    "            prec_pp,\n",
    "            cov_pp,\n",
    "        ) = self._automatic_posterior_transformation(\n",
    "            norm_logits_p, m_p, prec_p, norm_logits_d, m_d, prec_d\n",
    "        )\n",
    "\n",
    "        # Compute the log_prob of theta under the product.\n",
    "        log_prob_proposal_posterior = utils.mog_log_prob(\n",
    "            theta, logits_pp, m_pp, prec_pp\n",
    "        )\n",
    "        utils.assert_all_finite(\n",
    "            log_prob_proposal_posterior,\n",
    "            \"\"\"the evaluation of the MoG proposal posterior. This is likely due to a\n",
    "            numerical instability in the training procedure. Please create an issue on\n",
    "            Github.\"\"\",\n",
    "        )\n",
    "\n",
    "        return log_prob_proposal_posterior\n",
    "\n",
    "    def _automatic_posterior_transformation(\n",
    "        self,\n",
    "        logits_p: Tensor,\n",
    "        means_p: Tensor,\n",
    "        precisions_p: Tensor,\n",
    "        logits_d: Tensor,\n",
    "        means_d: Tensor,\n",
    "        precisions_d: Tensor,\n",
    "    ):\n",
    "        r\"\"\"Returns the MoG parameters of the proposal posterior.\n",
    "\n",
    "        The proposal posterior is:\n",
    "        $pp(\\theta|x) = 1/Z * q(\\theta|x) * prop(\\theta) / p(\\theta)$\n",
    "        In words: proposal posterior = posterior estimate * proposal / prior.\n",
    "\n",
    "        If the posterior estimate and the proposal are MoG and the prior is either\n",
    "        Gaussian or uniform, we can solve this in closed-form. The is implemented in\n",
    "        this function.\n",
    "\n",
    "        This function implements Appendix A1 from Greenberg et al. 2019.\n",
    "\n",
    "        We have to build L*K components. How do we do this?\n",
    "        Example: proposal has two components, density estimator has three components.\n",
    "        Let's call the two components of the proposal i,j and the three components\n",
    "        of the density estimator x,y,z. We have to multiply every component of the\n",
    "        proposal with every component of the density estimator. So, what we do is:\n",
    "        1) for the proposal, build: i,i,i,j,j,j. Done with torch.repeat_interleave()\n",
    "        2) for the density estimator, build: x,y,z,x,y,z. Done with torch.repeat()\n",
    "        3) Multiply them with simple matrix operations.\n",
    "\n",
    "        Args:\n",
    "            logits_p: Component weight of each Gaussian of the proposal.\n",
    "            means_p: Mean of each Gaussian of the proposal.\n",
    "            precisions_p: Precision matrix of each Gaussian of the proposal.\n",
    "            logits_d: Component weight for each Gaussian of the density estimator.\n",
    "            means_d: Mean of each Gaussian of the density estimator.\n",
    "            precisions_d: Precision matrix of each Gaussian of the density estimator.\n",
    "\n",
    "        Returns: (Component weight, mean, precision matrix, covariance matrix) of each\n",
    "            Gaussian of the proposal posterior. Has L*K terms (proposal has L terms,\n",
    "            density estimator has K terms).\n",
    "        \"\"\"\n",
    "\n",
    "        precisions_pp, covariances_pp = self._precisions_proposal_posterior(\n",
    "            precisions_p, precisions_d\n",
    "        )\n",
    "\n",
    "        means_pp = self._means_proposal_posterior(\n",
    "            covariances_pp, means_p, precisions_p, means_d, precisions_d\n",
    "        )\n",
    "\n",
    "        logits_pp = self._logits_proposal_posterior(\n",
    "            means_pp,\n",
    "            precisions_pp,\n",
    "            covariances_pp,\n",
    "            logits_p,\n",
    "            means_p,\n",
    "            precisions_p,\n",
    "            logits_d,\n",
    "            means_d,\n",
    "            precisions_d,\n",
    "        )\n",
    "\n",
    "        return logits_pp, means_pp, precisions_pp, covariances_pp\n",
    "\n",
    "    def _precisions_proposal_posterior(\n",
    "        self, precisions_p: Tensor, precisions_d: Tensor\n",
    "    ):\n",
    "        \"\"\"Return the precisions and covariances of the proposal posterior.\n",
    "\n",
    "        Args:\n",
    "            precisions_p: Precision matrices of the proposal distribution.\n",
    "            precisions_d: Precision matrices of the density estimator.\n",
    "\n",
    "        Returns: (Precisions, Covariances) of the proposal posterior. L*K terms.\n",
    "        \"\"\"\n",
    "\n",
    "        num_comps_p = precisions_p.shape[1]\n",
    "        num_comps_d = precisions_d.shape[1]\n",
    "\n",
    "        precisions_p_rep = precisions_p.repeat_interleave(num_comps_d, dim=1)\n",
    "        precisions_d_rep = precisions_d.repeat(1, num_comps_p, 1, 1)\n",
    "\n",
    "        precisions_pp = precisions_p_rep + precisions_d_rep\n",
    "        if isinstance(self._maybe_z_scored_prior, MultivariateNormal):\n",
    "            precisions_pp -= self._maybe_z_scored_prior.precision_matrix\n",
    "\n",
    "        covariances_pp = torch.inverse(precisions_pp)\n",
    "\n",
    "        return precisions_pp, covariances_pp\n",
    "\n",
    "    def _means_proposal_posterior(\n",
    "        self,\n",
    "        covariances_pp: Tensor,\n",
    "        means_p: Tensor,\n",
    "        precisions_p: Tensor,\n",
    "        means_d: Tensor,\n",
    "        precisions_d: Tensor,\n",
    "    ):\n",
    "        \"\"\"Return the means of the proposal posterior.\n",
    "\n",
    "        means_pp = C_ix * (P_i * m_i + P_x * m_x - P_o * m_o).\n",
    "\n",
    "        Args:\n",
    "            covariances_pp: Covariance matrices of the proposal posterior.\n",
    "            means_p: Means of the proposal distribution.\n",
    "            precisions_p: Precision matrices of the proposal distribution.\n",
    "            means_d: Means of the density estimator.\n",
    "            precisions_d: Precision matrices of the density estimator.\n",
    "\n",
    "        Returns: Means of the proposal posterior. L*K terms.\n",
    "        \"\"\"\n",
    "\n",
    "        num_comps_p = precisions_p.shape[1]\n",
    "        num_comps_d = precisions_d.shape[1]\n",
    "\n",
    "        # First, compute the product P_i * m_i and P_j * m_j\n",
    "        prec_m_prod_p = batched_mixture_mv(precisions_p, means_p)\n",
    "        prec_m_prod_d = batched_mixture_mv(precisions_d, means_d)\n",
    "\n",
    "        # Repeat them to allow for matrix operations: same trick as for the precisions.\n",
    "        prec_m_prod_p_rep = prec_m_prod_p.repeat_interleave(num_comps_d, dim=1)\n",
    "        prec_m_prod_d_rep = prec_m_prod_d.repeat(1, num_comps_p, 1)\n",
    "\n",
    "        # Means = C_ij * (P_i * m_i + P_x * m_x - P_o * m_o).\n",
    "        summed_cov_m_prod_rep = prec_m_prod_p_rep + prec_m_prod_d_rep\n",
    "        if isinstance(self._maybe_z_scored_prior, MultivariateNormal):\n",
    "            summed_cov_m_prod_rep -= self.prec_m_prod_prior\n",
    "\n",
    "        means_pp = batched_mixture_mv(covariances_pp, summed_cov_m_prod_rep)\n",
    "\n",
    "        return means_pp\n",
    "\n",
    "    @staticmethod\n",
    "    def _logits_proposal_posterior(\n",
    "        means_pp: Tensor,\n",
    "        precisions_pp: Tensor,\n",
    "        covariances_pp: Tensor,\n",
    "        logits_p: Tensor,\n",
    "        means_p: Tensor,\n",
    "        precisions_p: Tensor,\n",
    "        logits_d: Tensor,\n",
    "        means_d: Tensor,\n",
    "        precisions_d: Tensor,\n",
    "    ):\n",
    "        \"\"\"Return the component weights (i.e. logits) of the proposal posterior.\n",
    "\n",
    "        Args:\n",
    "            means_pp: Means of the proposal posterior.\n",
    "            precisions_pp: Precision matrices of the proposal posterior.\n",
    "            covariances_pp: Covariance matrices of the proposal posterior.\n",
    "            logits_p: Component weights (i.e. logits) of the proposal distribution.\n",
    "            means_p: Means of the proposal distribution.\n",
    "            precisions_p: Precision matrices of the proposal distribution.\n",
    "            logits_d: Component weights (i.e. logits) of the density estimator.\n",
    "            means_d: Means of the density estimator.\n",
    "            precisions_d: Precision matrices of the density estimator.\n",
    "\n",
    "        Returns: Component weights of the proposal posterior. L*K terms.\n",
    "        \"\"\"\n",
    "\n",
    "        num_comps_p = precisions_p.shape[1]\n",
    "        num_comps_d = precisions_d.shape[1]\n",
    "\n",
    "        # Compute log(alpha_i * beta_j)\n",
    "        logits_p_rep = logits_p.repeat_interleave(num_comps_d, dim=1)\n",
    "        logits_d_rep = logits_d.repeat(1, num_comps_p)\n",
    "        logit_factors = logits_p_rep + logits_d_rep\n",
    "\n",
    "        # Compute sqrt(det()/(det()*det()))\n",
    "        logdet_covariances_pp = torch.logdet(covariances_pp)\n",
    "        logdet_covariances_p = -torch.logdet(precisions_p)\n",
    "        logdet_covariances_d = -torch.logdet(precisions_d)\n",
    "\n",
    "        # Repeat the proposal and density estimator terms such that there are LK terms.\n",
    "        # Same trick as has been used above.\n",
    "        logdet_covariances_p_rep = logdet_covariances_p.repeat_interleave(\n",
    "            num_comps_d, dim=1\n",
    "        )\n",
    "        logdet_covariances_d_rep = logdet_covariances_d.repeat(1, num_comps_p)\n",
    "\n",
    "        log_sqrt_det_ratio = 0.5 * (\n",
    "            logdet_covariances_pp\n",
    "            - (logdet_covariances_p_rep + logdet_covariances_d_rep)\n",
    "        )\n",
    "\n",
    "        # Compute for proposal, density estimator, and proposal posterior:\n",
    "        # mu_i.T * P_i * mu_i\n",
    "        exponent_p = batched_mixture_vmv(precisions_p, means_p)\n",
    "        exponent_d = batched_mixture_vmv(precisions_d, means_d)\n",
    "        exponent_pp = batched_mixture_vmv(precisions_pp, means_pp)\n",
    "\n",
    "        # Extend proposal and density estimator exponents to get LK terms.\n",
    "        exponent_p_rep = exponent_p.repeat_interleave(num_comps_d, dim=1)\n",
    "        exponent_d_rep = exponent_d.repeat(1, num_comps_p)\n",
    "        exponent = -0.5 * (exponent_p_rep + exponent_d_rep - exponent_pp)\n",
    "\n",
    "        logits_pp = logit_factors + log_sqrt_det_ratio + exponent\n",
    "\n",
    "        return logits_pp\n",
    "\n",
    "    def _maybe_z_score_theta(self, theta: Tensor) -> Tensor:\n",
    "        \"\"\"Return potentially standardized theta if z-scoring was requested.\"\"\"\n",
    "\n",
    "        if self.z_score_theta:\n",
    "            theta, _ = self._neural_net._transform(theta)\n",
    "\n",
    "        return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## snpe gpu validate ######\n",
    "\n",
    "def validate_theta_and_x(\n",
    "    theta: Any, x: Any, data_device: str = \"gpu\", training_device: str = \"gpu\"\n",
    ") -> Tuple[Tensor, Tensor]:\n",
    "    r\"\"\"\n",
    "    Checks if the passed $(\\theta, x)$ are valid.\n",
    "\n",
    "    Specifically, we check:\n",
    "    1) If they are (torch) tensors.\n",
    "    2) If they have the same batchsize.\n",
    "    3) If they are of `dtype=float32`.\n",
    "\n",
    "    Additionally, We move the data to the specified `data_device`. This is where the\n",
    "    data is stored and can be separate from `training_device`, where the\n",
    "    computations for training are performed.\n",
    "\n",
    "    Raises:\n",
    "        AssertionError: If theta or x are not torch.Tensor-like,\n",
    "        do not yield the same batchsize and do not have dtype==float32.\n",
    "\n",
    "    Args:\n",
    "        theta: Parameters.\n",
    "        x: Simulation outputs.\n",
    "        data_device: Device where data is stored.\n",
    "        training_device: Training device for net.\n",
    "    \"\"\"\n",
    "    assert isinstance(theta, Tensor), \"Parameters theta must be a `torch.Tensor`.\"\n",
    "    assert isinstance(x, Tensor), \"Simulator output must be a `torch.Tensor`.\"\n",
    "\n",
    "    assert theta.shape[0] == x.shape[0], (\n",
    "        f\"Number of parameter sets (={theta.shape[0]} must match the number of \"\n",
    "        f\"simulation outputs (={x.shape[0]})\"\n",
    "    )\n",
    "\n",
    "    # I did not fuse these asserts with the `isinstance(x, Tensor)` asserts in order\n",
    "    # to give more explicit errors.\n",
    "    assert theta.dtype == float32, \"Type of parameters must be float32.\"\n",
    "    assert x.dtype == float32, \"Type of simulator outputs must be float32.\"\n",
    "\n",
    "    if str(x.device) != data_device:\n",
    "        warnings.warn(\n",
    "            f\"Data x has device '{x.device}'.\"\n",
    "            f\"Moving x to the data_device '{data_device}'.\"\n",
    "            f\"Training will proceed on device '{training_device}'.\"\n",
    "        )\n",
    "        x = x.to(data_device)\n",
    "\n",
    "    if str(theta.device) != data_device:\n",
    "        warnings.warn(\n",
    "            f\"Parameters theta has device '{theta.device}'. \"\n",
    "            f\"Moving theta to the data_device '{data_device}'.\"\n",
    "            f\"Training will proceed on device '{training_device}'.\"\n",
    "        )\n",
    "        theta = theta.to(data_device)\n",
    "\n",
    "    return theta, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bda45ebb03474fe784183fed4eaccaa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 100 simulations in 7 batches.:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Neural network successfully converged after 293 epochs."
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e1b3c9aab674f5c97442218b757812a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 100 posterior samples:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc6714b499c9438dbf77fcf4539f1cd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 100 simulations in 7 batches.:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SNPE-C with atomic loss\n",
      " Neural network successfully converged after 86 epochs."
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55fdc30c6cdc48ba89b6f390228d01ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 100 posterior samples:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Actual SNPE\n",
    "num_rounds = 2\n",
    "simulator_wrapper, prior = prepare_for_sbi(simulator, prior)\n",
    "\n",
    "\n",
    "# We define the neural network (neural density estimator), specifying the embedding net. In this case we use a mixture density network.\n",
    "neural_posterior = utils.posterior_nn(\n",
    "    model=\"maf\", embedding_net=embedding_net, hidden_features=50, num_transforms=3)\n",
    "\n",
    "# Setup the inference procedure with the SNPE-C (Greenberg et al, 2019)\n",
    "inference = SNPE(prior=prior, density_estimator=neural_posterior)\n",
    "\n",
    "posteriors = []\n",
    "proposal = prior\n",
    "\n",
    "num_simulations = 100\n",
    "simulation_batch_size = 15\n",
    "\n",
    "for _ in range(num_rounds):\n",
    "    theta, x = simulate_for_sbi(simulator_wrapper, proposal, num_simulations=num_simulations, simulation_batch_size=simulation_batch_size, num_workers=num_workers)\n",
    "    density_estimator = inference.append_simulations(\n",
    "        theta, x, proposal=proposal\n",
    "    ).train()\n",
    "    posterior = inference.build_posterior(density_estimator)\n",
    "    posteriors.append(posterior)\n",
    "    proposal = posterior.set_default_x(true_data)\n",
    "\n",
    "posterior_samples_RNN = posterior.sample((100,), x=true_data)\n",
    "_ = analysis.pairplot(\n",
    "    posterior_samples_RNN, limits=[[-100, 300], [-100, 300], [-100, 300]], figsize=(6, 6) #It should be close to 247, but since this is a toy example we are not expecting it to work (just checking it runs).\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try whether Athos- simulator works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 6])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### Simulate\n",
    "headers = [\"k1\" , \"k2\", \"k3\"]          # parameters to be inferred\n",
    "num_timesteps = 100\n",
    "\n",
    "# FOR SNLE\n",
    "prior_min = 0.01                        # same for all parameters\n",
    "prior_max = 250    \n",
    "\n",
    "t = np.linspace(0, 100, num_timesteps)\n",
    "\n",
    "param_dict = {'k1': 246.96291990024542, 'k2': 246.96291990024542, 'k3': 246.96291990024542, 'n1': 5, 'n2': 5, 'n3': 5, 'dm1': 1.143402097500176, 'dm2': 1.143402097500176, 'dm3': 1.143402097500176, 'dp1': 0.7833664565550977, 'dp2': 0.7833664565550977, 'dp3': 0.7833664565550977,\n",
    "              'a1': 24.78485282457379, 'a2': 24.78485282457379, 'a3': 24.78485282457379, 'g1': 0.024884149937163258, 'g2': 0.024884149937163258, 'g3': 0.024884149937163258, 'b1': 33.82307682700831, 'b2': 33.82307682700831, 'b3': 33.82307682700831}\n",
    "\n",
    "all_params = 'a1', 'a2', 'a3', 'g1', 'g2', 'g3', 'dm1', 'dm2', 'dm3', 'dp1', 'dp2', 'dp3', 'b1', 'b2', 'b3', 'n1', 'n2', 'n3', 'k1', 'k2', 'k3'\n",
    "new_param_dict ={}\n",
    "for param in all_params:\n",
    "    if param not in headers:\n",
    "        new_param_dict[param] = param_dict[param]\n",
    "    elif param in headers:\n",
    "        new_param_dict[param] = param\n",
    "\n",
    "def my_simulator(theta):\n",
    "    def model(variables, t, theta, new_param_dict = new_param_dict):\n",
    "        m1, p1, m2, p2, m3, p3 = variables\n",
    "        for i in range(len(headers)):\n",
    "            new_param_dict[headers[i]] = theta[i]\n",
    "        \n",
    "        dm1dt = -new_param_dict['dm1']*m1 + (new_param_dict['a1'] / (1 + ((1/new_param_dict['k1']) * p2)**new_param_dict['n1'])) + new_param_dict['g1']\n",
    "        dp1dt = (new_param_dict['b1']*m1) - (new_param_dict['dp1']*p1)\n",
    "        dm2dt = -new_param_dict['dm2']*m2 + (new_param_dict['a2'] / (1 + ((1/new_param_dict['k2']) * p3)**new_param_dict['n2'])) + new_param_dict['g2']\n",
    "        dp2dt = (new_param_dict['b2']*m2) - (new_param_dict['dp2']*p2)\n",
    "        dm3dt = -new_param_dict['dm3']*m3 + (new_param_dict['a3'] / (1 + ((1/new_param_dict['k3']) * p1)**new_param_dict['n3'])) + new_param_dict['g3']\n",
    "        dp3dt = (new_param_dict['b3']*m3) - (new_param_dict['dp3']*p3)\n",
    "\n",
    "        return [dm1dt, dp1dt, dm2dt, dp2dt, dm3dt, dp3dt]\n",
    "\n",
    "    def solve_ode(theta, t):\n",
    "        initial_conditions = np.array([0, 2, 0, 1, 0, 3], dtype=np.float32)\n",
    "        y = odeint(model, initial_conditions, t, args=(theta,))\n",
    "                 #raw output\n",
    "        return torch.tensor(y, dtype=torch.float32)\n",
    "    return solve_ode(theta, t)\n",
    "prior = utils.BoxUniform(\n",
    "    low=torch.tensor([10**-2,10**-2,10**-2]),\n",
    "    high=torch.tensor([250.,250.,250.]))\n",
    "true_params = tuple(param_dict[parameter] for parameter in headers)\n",
    "true_data = my_simulator(true_params)\n",
    "num_dim = len(true_params)\n",
    "true_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator_wrapper, prior = prepare_for_sbi(my_simulator, prior)\n",
    "batch_size = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 100, 6])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fourdim = simulator_wrapper(prior.sample((batch_size,)))\n",
    "fourdim.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try actual SNPE from .py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs (torch.cuda.device_count()): 0\n",
      "Number of CPUs (multiprocessing.cpu_count()): 8\n",
      "Number of CPUs (os.cpu_count()): 8\n"
     ]
    }
   ],
   "source": [
    "### IMPORT PACKAGES AND ALSO REWRITE FUNCTIONS ###\n",
    "\n",
    "import torch\n",
    "import multiprocessing\n",
    "import os\n",
    "\n",
    "def get_gpu_count():\n",
    "    return torch.cuda.device_count()\n",
    "\n",
    "def get_cpu_count():\n",
    "    return multiprocessing.cpu_count()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    num_gpus = get_gpu_count()\n",
    "    num_cpus = get_cpu_count()\n",
    "    print(\"Number of GPUs (torch.cuda.device_count()):\", num_gpus)\n",
    "    print(\"Number of CPUs (multiprocessing.cpu_count()):\", num_cpus)\n",
    "\n",
    "print(\"Number of CPUs (os.cpu_count()):\", os.cpu_count())\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import odeint\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sbi.inference import SNPE, prepare_for_sbi, simulate_for_sbi\n",
    "from sbi import utils as utils\n",
    "from sbi import analysis as analysis\n",
    "from sbi.inference.base import infer\n",
    "import numpy as np\n",
    "\n",
    "import joblib\n",
    "import math\n",
    "from math import ceil\n",
    "import random\n",
    "import contextlib\n",
    "import torch\n",
    "import sys\n",
    "from numpy import fft, ndarray\n",
    "from scipy.stats import norm\n",
    "import os\n",
    "import seaborn as sns\n",
    "from pyro.infer.mcmc.api import MCMC\n",
    "from warnings import warn\n",
    "from torch import Tensor, split, randint, cat\n",
    "from typing import Any, Callable, Optional, Tuple, Union, Dict\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "from tqdm.auto import tqdm, trange\n",
    "from pyro.infer.mcmc import HMC, NUTS\n",
    "from sbi.inference import prepare_for_sbi, SNLE\n",
    "from sbi import utils as utils\n",
    "from sbi import analysis as analysis\n",
    "from sbi.types import Shape, TorchTransform\n",
    "from sbi.utils.get_nn_models import (likelihood_nn,)\n",
    "from sbi.samplers.mcmc import SliceSamplerVectorized\n",
    "from sbi.samplers.mcmc.slice_numpy import MCMCSampler\n",
    "from sbi.utils import tensor2numpy\n",
    "\n",
    "def seed_all_backends(seed: Optional[Union[int, Tensor]] = None) -> None:\n",
    "    if seed is None:\n",
    "        seed = int(torch.randint(10_000_000, size=(1,)))\n",
    "    else:\n",
    "        # Cast Tensor to int (required by math.random since Python 3.11)\n",
    "        seed = int(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True # type: ignore\n",
    "    torch.backends.cudnn.benchmark = False # type: ignore\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def tqdm_joblib(tqdm_object):\n",
    "    def tqdm_print_progress(self):\n",
    "        if self.n_completed_tasks > tqdm_object.n:\n",
    "            n_completed = self.n_completed_tasks - tqdm_object.n\n",
    "            tqdm_object.update(n=n_completed)\n",
    "    \n",
    "    original_print_progress = joblib.parallel.Parallel.print_progress\n",
    "    joblib.parallel.Parallel.print_progress = tqdm_print_progress\n",
    "    \n",
    "    try:\n",
    "        yield tqdm_object\n",
    "    finally:\n",
    "        joblib.parallel.Parallel.print_progress = original_print_progress\n",
    "        tqdm_object.close()\n",
    "\n",
    "class SliceSampler(MCMCSampler):\n",
    "    def __init__(self, x, lp_f, max_width=float(\"inf\"), init_width: Union[float, np.ndarray] = 0.05, thin=None, tuning: int = 50, verbose: bool = False,):\n",
    "        MCMCSampler.__init__(self, x, lp_f, thin, verbose=verbose)\n",
    "        self.max_width = max_width\n",
    "        self.init_width = init_width\n",
    "        self.width = None\n",
    "        self.tuning = tuning\n",
    "        \n",
    "    def _tune_bracket_width(self, rng):\n",
    "        order = list(range(self.n_dims))\n",
    "        x = self.x.copy()\n",
    "\n",
    "        self.width = np.full(self.n_dims, self.init_width)\n",
    "\n",
    "        tbar = trange(self.tuning, miniters=2, disable=not self.verbose)\n",
    "        tbar.set_description(\"Tuning bracket width...\")\n",
    "        for n in tbar:\n",
    "            # for n in range(int(self.tuning)):\n",
    "            rng.shuffle(order)\n",
    "            for i in range(self.n_dims):\n",
    "                x[i], wi = self._sample_from_conditional(i, x[i], rng)\n",
    "                self.width[i] += (wi - self.width[i]) / (n + 1)\n",
    "\n",
    "    def _sample_from_conditional(self, i: int, cxi, rng):\n",
    "        assert self.width is not None, \"Chain not initialized.\"\n",
    "\n",
    "        # conditional log prob\n",
    "        Li = lambda t: self.lp_f(np.concatenate([self.x[:i], [t], self.x[i + 1 :]]))\n",
    "        wi = self.width[i]\n",
    "\n",
    "        # sample a slice uniformly\n",
    "        logu = Li(cxi) + np.log(1.0 - rng.rand())\n",
    "\n",
    "        # position the bracket randomly around the current sample\n",
    "        lx = cxi - wi * rng.rand()\n",
    "        ux = lx + wi\n",
    "        \n",
    "        # find lower bracket end\n",
    "        while Li(lx) >= logu and cxi - lx < self.max_width:\n",
    "            lx -= wi\n",
    "\n",
    "        # find upper bracket end\n",
    "        while Li(ux) >= logu and ux - cxi < self.max_width:\n",
    "            ux += wi\n",
    "\n",
    "        # sample uniformly from bracket\n",
    "        xi = (ux - lx) * rng.rand() + lx\n",
    "\n",
    "        # if outside slice, reject sample and shrink bracket\n",
    "        while Li(xi) < logu:\n",
    "            if xi < cxi:\n",
    "                lx = xi\n",
    "            else:\n",
    "                ux = xi\n",
    "            xi = (ux - lx) * rng.rand() + lx\n",
    "       \n",
    "        return xi, ux - lx\n",
    "      \n",
    "def run_fun(SliceSamplerSerial, num_samples, inits, seed, log_prob_fn: Callable, thin: Optional[int] = None, tuning: int = 50, verbose: bool = True, init_width: Union[float, np.ndarray] = 0.01,\n",
    "            max_width: float = float(\"inf\"), num_workers: int = 1, rng=np.random, show_info: bool = False, logger=sys.stdout) -> np.ndarray:\n",
    "    np.random.seed(seed)\n",
    "    posterior_sampler = SliceSampler(inits, lp_f=log_prob_fn, max_width=max_width, init_width=init_width, thin=thin, tuning=tuning, verbose=num_workers == 1 and verbose,)\n",
    "    \n",
    "    assert num_samples >= 0, \"number of samples can't be negative\"\n",
    "\n",
    "    order = list(range(posterior_sampler.n_dims))\n",
    "    L_trace = []\n",
    "    samples = np.empty([int(num_samples), int(posterior_sampler.n_dims)])\n",
    "    logger = open(os.devnull, \"w\") if logger is None else logger\n",
    "\n",
    "    if posterior_sampler.width is None:\n",
    "        # logger.write('tuning bracket width...\\n')\n",
    "        posterior_sampler._tune_bracket_width(rng)\n",
    "\n",
    "    tbar = trange(int(num_samples), miniters=10, disable=not posterior_sampler.verbose)\n",
    "    tbar.set_description(\"Generating samples\")\n",
    "    for n in tbar:\n",
    "        # for n in range(int(n_samples)):\n",
    "        for _ in range(posterior_sampler.thin):\n",
    "            rng.shuffle(order)\n",
    "\n",
    "            for i in order:\n",
    "                posterior_sampler.x[i], _ = posterior_sampler._sample_from_conditional(i, posterior_sampler.x[i], rng)\n",
    "\n",
    "        samples[n] = posterior_sampler.x.copy()\n",
    "\n",
    "        posterior_sampler.L = posterior_sampler.lp_f(posterior_sampler.x)\n",
    "        # logger.write('sample = {0}, log prob = {1:.2}\\n'.format(n+1, self.L))\n",
    "\n",
    "        if show_info:\n",
    "            L_trace.append(posterior_sampler.L)\n",
    "\n",
    "    # show trace plot\n",
    "    if show_info:\n",
    "        fig, ax = plt.subplots(1, 1)\n",
    "        ax.plot(L_trace)\n",
    "        ax.set_ylabel(\"log probability\")\n",
    "        ax.set_xlabel(\"samples\")\n",
    "        plt.show(block=False)\n",
    "\n",
    "    return samples\n",
    "\n",
    "def run(SliceSamplerSerial, log_prob_fn: Callable, num_samples: int, init_params: np.ndarray, num_chains: int = 1, thin: Optional[int] = None, verbose: bool = True, num_workers: int = 1,) -> np.ndarray:\n",
    "    num_chains , dim_samples = init_params.shape\n",
    "    # Generate seeds for workers from current random state.\n",
    "    seeds = torch.randint(high=1_000_000, size=(num_chains,))\n",
    "    for seed in seeds:\n",
    "        seed_all_backends(seed)\n",
    "    with tqdm_joblib(tqdm(range(num_chains), disable=not verbose, desc=f\"\"\"Running {num_chains} MCMC chains with {num_workers} worker{\"s\" if num_workers>1 else \"\"}.\"\"\", total=num_chains,)):\n",
    "        all_samples = Parallel(n_jobs=num_workers)(delayed(run_fun)(SliceSamplerSerial, num_samples, initial_params_batch, seed, log_prob_fn)for initial_params_batch, seed in zip(init_params, seeds))\n",
    "    samples = np.stack(all_samples).astype(np.float32)\n",
    "    samples = samples.reshape(num_chains, -1, dim_samples)  # chains, samples, dim\n",
    "    samples = samples[:, :: thin, :]  # thin chains\n",
    "\n",
    "    # save samples\n",
    "    return samples\n",
    "\n",
    "class SliceSamplerSerial:\n",
    "    def __init__(self, log_prob_fn: Callable, init_params: np.ndarray, num_chains: int = 1, thin: Optional[int] = None, tuning: int = 50, verbose: bool = True, init_width: Union[float, np.ndarray] = 0.01, max_width: float = float(\"inf\"), num_workers: int = 1,):\n",
    "        self._log_prob_fn = log_prob_fn\n",
    "        self.x = init_params\n",
    "        self.num_chains = num_chains\n",
    "        self.thin = thin\n",
    "        self.tuning = tuning\n",
    "        self.verbose = verbose\n",
    "        self.init_width = init_width\n",
    "        self.max_width = max_width\n",
    "        self.n_dims = self.x.size\n",
    "        self.num_workers = num_workers\n",
    "        self._samples = None\n",
    "\n",
    "    def get_samples(self, num_samples: Optional[int] = None, group_by_chain: bool = True) -> np.ndarray:\n",
    "        if self._samples is None:\n",
    "            raise ValueError(\"No samples found from MCMC run.\")\n",
    "        # if not grouped by chain, flatten samples into (all_samples, dim_params)\n",
    "        if not group_by_chain:\n",
    "            samples = self._samples.reshape(-1, self._samples.shape[2])\n",
    "        else:\n",
    "            samples = self._samples\n",
    "\n",
    "        # if not specified return all samples\n",
    "        if num_samples is None:\n",
    "            return samples\n",
    "        # otherwise return last num_samples (for each chain when grouped).\n",
    "        elif group_by_chain:\n",
    "            return samples[:, -num_samples:, :]\n",
    "        else:\n",
    "            return samples[-num_samples:, :]\n",
    "\n",
    "##############################################################################################################################\n",
    "        \n",
    "def _maybe_use_dict_entry(default: Any, key: str, dict_to_check: Dict) -> Any:\n",
    "    attribute = default if key not in dict_to_check.keys() else dict_to_check[key]\n",
    "    return attribute\n",
    "\n",
    "def _get_initial_params(proposal, init_strategy: str, num_chains: int, num_workers: int, show_progress_bars: bool, **kwargs,) -> Tensor: \n",
    "    # Build init function\n",
    "    init_fn = proposal._build_mcmc_init_fn(proposal.proposal, proposal.potential_fn, transform=proposal.theta_transform, init_strategy=init_strategy, **kwargs,)\n",
    "\n",
    "    # Parallelize inits for resampling only.\n",
    "    if num_workers > 1 and (init_strategy == \"resample\" or init_strategy == \"sir\"):\n",
    "        def seeded_init_fn(seed):\n",
    "            torch.manual_seed(seed)\n",
    "            return init_fn()\n",
    "\n",
    "        seeds = torch.randint(high=10_000_000, size=(num_chains,))\n",
    "\n",
    "        # Generate initial params parallelized over num_workers.\n",
    "        with tqdm_joblib(tqdm(range(num_chains), disable=not show_progress_bars, desc=f\"\"\"Generating {num_chains} MCMC inits with {num_workers} workers.\"\"\", total=num_chains,)):\n",
    "            initial_params = torch.cat(Parallel(n_jobs=num_workers)(delayed(seeded_init_fn)(seed) for seed in seeds))\n",
    "    else:\n",
    "        initial_params = torch.cat([init_fn() for _ in range(num_chains)])\n",
    "    return initial_params\n",
    "    \n",
    "def _slice_np_mcmc(proposal, num_samples: int, potential_function: Callable, initial_params: Tensor, thin: int, warmup_steps: int, vectorized: bool = False, num_workers: int = 1, init_width: Union[float, ndarray] = 0.01, show_progress_bars: bool = True,) -> Tensor:\n",
    "    num_chains, dim_samples = initial_params.shape\n",
    "        \n",
    "    if not vectorized:\n",
    "        SliceSamplerMultiChain = SliceSamplerSerial\n",
    "    else:\n",
    "        SliceSamplerMultiChain = SliceSamplerVectorized\n",
    "\n",
    "    posterior_sampler = SliceSamplerMultiChain(init_params=tensor2numpy(initial_params), log_prob_fn=potential_function, num_chains=num_chains, thin=thin, verbose=show_progress_bars, num_workers=num_workers, init_width=init_width,)\n",
    "    warmup_ = warmup_steps * thin\n",
    "    num_samples_ = ceil((num_samples * thin) / num_chains)\n",
    "    # Run mcmc including warmup\n",
    "    samples = run(posterior_sampler, log_prob_fn=potential_function, num_samples = (warmup_ + num_samples_), init_params = tensor2numpy(initial_params))\n",
    "    samples = samples[:, warmup_steps:, :]  # discard warmup steps\n",
    "    samples = torch.from_numpy(samples)  # chains x samples x dim\n",
    "\n",
    "    # Save posterior sampler.\n",
    "    proposal._posterior_sampler = posterior_sampler\n",
    "\n",
    "    # Save sample as potential next init (if init_strategy == 'latest_sample').\n",
    "    proposal._mcmc_init_params = samples[:, -1, :].reshape(num_chains, dim_samples)\n",
    "\n",
    "    # Collect samples from all chains.\n",
    "    samples = samples.reshape(-1, dim_samples)[:num_samples, :]\n",
    "    assert samples.shape[0] == num_samples\n",
    "    return samples.type(torch.float32).to(proposal._device)\n",
    "\n",
    "def sample_my_fun(proposal, sample_shape: Shape = torch.Size(), x: Optional[Tensor] = None, method: Optional[str] = None, thin: Optional[int] = None, warmup_steps: Optional[int] = None, num_chains: Optional[int] = None, init_strategy: Optional[str] = None, init_strategy_parameters: Optional[Dict[str, Any]] = None,\n",
    "                   init_strategy_num_candidates: Optional[int] = None, mcmc_parameters: Dict = {}, mcmc_method: Optional[str] = None, sample_with: Optional[str] = None, num_workers: Optional[int] = None, show_progress_bars: bool = True,) -> Tensor:\n",
    "    \n",
    "    proposal.potential_fn.set_x(proposal._x_else_default_x(x))\n",
    "\n",
    "    # Replace arguments that were not passed with their default.\n",
    "    method = proposal.method if method is None else method\n",
    "    thin = proposal.thin if thin is None else thin\n",
    "    warmup_steps = proposal.warmup_steps if warmup_steps is None else warmup_steps\n",
    "    num_chains = proposal.num_chains if num_chains is None else num_chains\n",
    "    init_strategy = proposal.init_strategy if init_strategy is None else init_strategy\n",
    "    num_workers = proposal.num_workers if num_workers is None else num_workers\n",
    "    init_strategy_parameters = (proposal.init_strategy_parameters if init_strategy_parameters is None else init_strategy_parameters)\n",
    "\n",
    "    if init_strategy_num_candidates is not None:\n",
    "        warn(\"\"\"Passing `init_strategy_num_candidates` is deprecated as of sbi v0.19.0. Instead, use e.g.,`init_strategy_parameters={\"num_candidate_samples\": 1000}`\"\"\")\n",
    "        proposal.init_strategy_parameters[\"num_candidate_samples\"] = (init_strategy_num_candidates)\n",
    "    if sample_with is not None:\n",
    "        raise ValueError(f\"You set `sample_with={sample_with}`. As of sbi v0.18.0, setting `sample_with` is no longer supported. You have to rerun `.build_posterior(sample_with={sample_with}).`\")\n",
    "    if mcmc_method is not None:\n",
    "        warn(\"You passed `mcmc_method` to `.sample()`. As of sbi v0.18.0, this is deprecated and will be removed in a future release. Use `method` instead of `mcmc_method`.\")\n",
    "        method = mcmc_method\n",
    "    if mcmc_parameters:\n",
    "        warn(\"You passed `mcmc_parameters` to `.sample()`. As of sbi v0.18.0, this is deprecated and will be removed in a future release. Instead, pass the variable to `.sample()` directly, e.g. `posterior.sample((1,), num_chains=5)`.\")\n",
    "    # The following lines are only for backwards compatibility with sbi v0.17.2 or older.\n",
    "    m_p = mcmc_parameters  # define to shorten the variable name\n",
    "    method = _maybe_use_dict_entry(method, \"mcmc_method\", m_p)\n",
    "    thin = _maybe_use_dict_entry(thin, \"thin\", m_p)\n",
    "    warmup_steps = _maybe_use_dict_entry(warmup_steps, \"warmup_steps\", m_p)\n",
    "    num_chains = _maybe_use_dict_entry(num_chains, \"num_chains\", m_p)\n",
    "    init_strategy = _maybe_use_dict_entry(init_strategy, \"init_strategy\", m_p)\n",
    "    proposal.potential_ = proposal._prepare_potential(method)  # type: ignore\n",
    "\n",
    "    initial_params = _get_initial_params(proposal, init_strategy, num_chains, num_workers, show_progress_bars, **init_strategy_parameters,)\n",
    "    num_samples = torch.Size(sample_shape).numel()\n",
    "\n",
    "    track_gradients = method in (\"hmc\", \"nuts\")\n",
    "    with torch.set_grad_enabled(track_gradients):\n",
    "        if method in (\"slice_np\", \"slice_np_vectorized\"):\n",
    "            transformed_samples = _slice_np_mcmc(proposal, num_samples=num_samples, potential_function=proposal.potential_, initial_params=initial_params, thin=thin, warmup_steps=warmup_steps, vectorized=(method == \"slice_np_vectorized\"), num_workers=num_workers, show_progress_bars=show_progress_bars,)\n",
    "        elif method in (\"hmc\", \"nuts\", \"slice\"):\n",
    "            transformed_samples = _pyro_mcmc(proposal, num_samples=num_samples, potential_function=proposal.potential_, initial_params=initial_params, mcmc_method=method, thin=thin, warmup_steps=warmup_steps, num_chains=num_chains, show_progress_bars=show_progress_bars,)\n",
    "        else:\n",
    "            raise NameError\n",
    "\n",
    "    samples = proposal.theta_transform.inv(transformed_samples)\n",
    "\n",
    "    return samples.reshape((*sample_shape, -1))  # type: ignore\n",
    "\n",
    "#######################################################################################################################################\n",
    "\n",
    "def simulator_seeded(simulator: Callable, theta: Tensor, seed: int) -> Tensor:\n",
    "    import torch\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    with torch.random.fork_rng(devices=[]):\n",
    "        torch.manual_seed(seed)\n",
    "        return simulator(theta)\n",
    "\n",
    "def simulate_in_batches(simulator: Callable, theta: Tensor, sim_batch_size: int = 1, num_workers: int = 1 , seed: Optional[int] = None, show_progress_bars: bool = True, ) -> Tensor:\n",
    "    num_sims, *_ = theta.shape\n",
    "    seed_all_backends(seed)\n",
    "    if num_sims == 0:\n",
    "        x = torch.tensor([])\n",
    "    elif sim_batch_size is not None and sim_batch_size < num_sims:\n",
    "        batches = split(theta, sim_batch_size, dim=0)\n",
    "        \n",
    "        if num_workers != 1:\n",
    "            batch_seeds = randint(high=1_000_000, size=(len(batches),))\n",
    "            with tqdm_joblib(tqdm(batches, disable=not show_progress_bars, total = len(batches), desc=f\"Running {num_sims} simulations in {len(batches)} batches ({num_workers} cores)\",)) as _:\n",
    "                simulation_outputs = Parallel(n_jobs=num_workers)(delayed(simulator_seeded)(simulator, batch, batch_seed) for batch, batch_seed in zip(batches, batch_seeds))\n",
    "        else:\n",
    "            pbar = tqdm(total=num_sims, disable=not show_progress_bars, desc=f\"Running {num_sims} simulations.\", )\n",
    "            with pbar:\n",
    "                simulation_outputs = []\n",
    "                for batch in batches:\n",
    "                    simulation_outputs.append(simulator_seeded(simulator, batch, seed))\n",
    "                    pbar.update(sim_batch_size)\n",
    "        x = cat(simulation_outputs, dim=0)\n",
    "    else:\n",
    "        x = simulator(theta)\n",
    "    return x\n",
    "\n",
    "def simulate_for_sbi(round_idx: int, simulator: Callable, proposal: Any, num_simulations: int, num_workers: int = 1, simulation_batch_size: int = 1, seed: Optional[int] = None, show_progress_bar: bool = True)-> Tuple[Tensor, Tensor]:\n",
    "    if round_idx == 0:\n",
    "        theta = proposal.sample((num_simulations,))\n",
    "    else:\n",
    "        theta = sample_my_fun(proposal, (num_simulations,), num_workers = num_workers, num_chains = 4) # because only in first round proposal is boxuniform, then it is mcmcposterior object\n",
    "    \n",
    "    x = simulate_in_batches(simulator=simulator, theta=theta, sim_batch_size=simulation_batch_size, num_workers=num_workers, seed=seed, show_progress_bars=show_progress_bar)\n",
    "    \n",
    "    return theta, x\n",
    "\n",
    "### Parallelisation ###\n",
    "##### paralellise #####\n",
    "\n",
    "#Parallelise it\n",
    "# PART 1: Edited code from original sbi repos. Functions edited: simulate_for_sbi, and all the functions it contains.\n",
    "#Main changes: defined simulator_seeded globally rather than within simulate_in_batches function, and re-imported torch within simulator_seeded \n",
    "#NO changes need to be made in this file\n",
    "\n",
    "# PART 2: Essentially the unparallelised code with 2 extra arguments in the simulate_for_sbi line\n",
    "\n",
    "##################################### PART 1 #########################################\n",
    "import joblib\n",
    "import contextlib\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from torch import Tensor, split, randint, cat\n",
    "from typing import Any, Callable, Optional, Tuple, Union\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import sbi\n",
    "from scipy.integrate import odeint\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sbi.inference import SNLE, prepare_for_sbi\n",
    "# No longer importing simulate_for_sbi from the package, we use the one defined above\n",
    "from sbi import utils as utils\n",
    "from sbi import analysis as analysis\n",
    "\n",
    "def seed_all_backends(seed: Optional[Union[int, Tensor]] = None) -> None:\n",
    "    if seed is None:\n",
    "        seed = int(torch.randint(1_000_000, size=(1,)))\n",
    "    else:\n",
    "        # Cast Tensor to int (required by math.random since Python 3.11)\n",
    "        seed = int(seed)\n",
    "\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True # type: ignore\n",
    "    torch.backends.cudnn.benchmark = False # type: ignore\n",
    "\n",
    "def simulator_seeded(simulator: Callable, theta: Tensor, seed: int) -> Tensor:\n",
    "    import torch\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    with torch.random.fork_rng(devices=[]):\n",
    "        torch.manual_seed(seed)\n",
    "        return simulator(theta)\n",
    "\n",
    "def simulate_in_batches(simulator: Callable, theta: Tensor, sim_batch_size: int = 1, num_workers: int = 1,\n",
    "                        seed: Optional[int] = None, show_progress_bars: bool = True, ) -> Tensor:\n",
    "\n",
    "    num_sims, *_ = theta.shape\n",
    "    seed_all_backends(seed)\n",
    "\n",
    "    if num_sims == 0:\n",
    "        x = torch.tensor([])\n",
    "    elif sim_batch_size is not None and sim_batch_size < num_sims:\n",
    "        batches = split(theta, sim_batch_size, dim=0)\n",
    "\n",
    "        if num_workers != 1:\n",
    "            batch_seeds = randint(high=1_000_000, size=(len(batches),))\n",
    "\n",
    "            with tqdm_joblib(\n",
    "                tqdm(batches, disable=not show_progress_bars,\n",
    "                     desc=f\"Running {num_sims} simulations in {len(batches)} batches.\", total=len(batches),)) as _:\n",
    "                simulation_outputs = Parallel(n_jobs=num_workers)(delayed(simulator_seeded)(simulator, batch, batch_seed)\n",
    "                    for batch, batch_seed in zip(batches, batch_seeds))\n",
    "        else:\n",
    "            pbar = tqdm(total=num_sims, disable=not show_progress_bars, desc=f\"Running {num_sims} simulations.\", )\n",
    "\n",
    "            with pbar:\n",
    "                simulation_outputs = []\n",
    "                for batch in batches:\n",
    "                    simulation_outputs.append(simulator_seeded(simulator, batch, seed))\n",
    "                    pbar.update(sim_batch_size)\n",
    "\n",
    "        x = cat(simulation_outputs, dim=0)\n",
    "    else:\n",
    "        x = simulator(theta)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def tqdm_joblib(tqdm_object):\n",
    "    def tqdm_print_progress(self):\n",
    "        if self.n_completed_tasks > tqdm_object.n:\n",
    "            n_completed = self.n_completed_tasks - tqdm_object.n\n",
    "            tqdm_object.update(n=n_completed)\n",
    "\n",
    "    original_print_progress = joblib.parallel.Parallel.print_progress\n",
    "    joblib.parallel.Parallel.print_progress = tqdm_print_progress\n",
    "\n",
    "    try:\n",
    "        yield tqdm_object\n",
    "    finally:\n",
    "        joblib.parallel.Parallel.print_progress = original_print_progress\n",
    "        tqdm_object.close()\n",
    "\n",
    "def simulate_for_sbi(simulator: Callable, proposal: Any, num_simulations: int, num_workers: int = 1,\n",
    "                     simulation_batch_size: int = 1, seed: Optional[int] = None,\n",
    "                     show_progress_bar: bool = True, ) -> Tuple[Tensor, Tensor]:\n",
    "\n",
    "    theta = proposal.sample((num_simulations,))\n",
    "\n",
    "    x = simulate_in_batches(simulator=simulator, theta=theta, sim_batch_size=simulation_batch_size,\n",
    "                            num_workers=num_workers, seed=seed, show_progress_bars=show_progress_bar,)\n",
    "\n",
    "    return theta, x\n",
    "\n",
    "######################################################################################################\n",
    "\n",
    "# To parallelise, set number of CPUs to be used. Note: parallelise anything that has num_rounds>2 and/or num_simulations>50\n",
    "# to see total available CPUs: print(os.cpu_count())\n",
    "\n",
    "CPUs_to_use = 8\n",
    "\n",
    "total_CPUs = os.cpu_count()\n",
    "num_workers = CPUs_to_use - total_CPUs -1\n",
    "# num_workers = -1 uses all cpus\n",
    "# num_workers = -2 uses all cpus but one etc https://joblib.readthedocs.io/en/latest/generated/joblib.Parallel.html\n",
    "if CPUs_to_use > total_CPUs:\n",
    "    raise ValueError(f\"Cannot use more CPUs than are available. Available CPUs: {total_CPUs}\")\n",
    "\n",
    "######################################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f85d72373dd43e3bd3369587d8df613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 100 simulations in 7 batches.:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Neural network successfully converged after 63 epochs."
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23e2fd085ea7480b8a7f604217968187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0caeb04842724ce8872aee089c7b137d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9803f9e28370413fbe63985e5ae62dca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 100 simulations in 7 batches.:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SNPE-C with atomic loss\n",
      " Neural network successfully converged after 94 epochs."
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8792e66dba4e42ab9c33d158836fd1bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a1c7a1cc5e9429eb9d9e05b772866ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Simulator\n",
    "###### Simulate\n",
    "headers = [\"k1\" , \"k2\", \"k3\"]          # parameters to be inferred\n",
    "num_timesteps = 100\n",
    "\n",
    "# FOR SNLE\n",
    "prior_min = 0.01                        # same for all parameters\n",
    "prior_max = 250    \n",
    "\n",
    "t = np.linspace(0, 100, num_timesteps)\n",
    "\n",
    "param_dict = {'k1': 246.96291990024542, 'k2': 246.96291990024542, 'k3': 246.96291990024542, 'n1': 5, 'n2': 5, 'n3': 5, 'dm1': 1.143402097500176, 'dm2': 1.143402097500176, 'dm3': 1.143402097500176, 'dp1': 0.7833664565550977, 'dp2': 0.7833664565550977, 'dp3': 0.7833664565550977,\n",
    "              'a1': 24.78485282457379, 'a2': 24.78485282457379, 'a3': 24.78485282457379, 'g1': 0.024884149937163258, 'g2': 0.024884149937163258, 'g3': 0.024884149937163258, 'b1': 33.82307682700831, 'b2': 33.82307682700831, 'b3': 33.82307682700831}\n",
    "\n",
    "all_params = 'a1', 'a2', 'a3', 'g1', 'g2', 'g3', 'dm1', 'dm2', 'dm3', 'dp1', 'dp2', 'dp3', 'b1', 'b2', 'b3', 'n1', 'n2', 'n3', 'k1', 'k2', 'k3'\n",
    "new_param_dict ={}\n",
    "for param in all_params:\n",
    "    if param not in headers:\n",
    "        new_param_dict[param] = param_dict[param]\n",
    "    elif param in headers:\n",
    "        new_param_dict[param] = param\n",
    "\n",
    "def my_simulator(theta):\n",
    "    def model(variables, t, theta, new_param_dict = new_param_dict):\n",
    "        m1, p1, m2, p2, m3, p3 = variables\n",
    "        for i in range(len(headers)):\n",
    "            new_param_dict[headers[i]] = theta[i]\n",
    "        \n",
    "        dm1dt = -new_param_dict['dm1']*m1 + (new_param_dict['a1'] / (1 + ((1/new_param_dict['k1']) * p2)**new_param_dict['n1'])) + new_param_dict['g1']\n",
    "        dp1dt = (new_param_dict['b1']*m1) - (new_param_dict['dp1']*p1)\n",
    "        dm2dt = -new_param_dict['dm2']*m2 + (new_param_dict['a2'] / (1 + ((1/new_param_dict['k2']) * p3)**new_param_dict['n2'])) + new_param_dict['g2']\n",
    "        dp2dt = (new_param_dict['b2']*m2) - (new_param_dict['dp2']*p2)\n",
    "        dm3dt = -new_param_dict['dm3']*m3 + (new_param_dict['a3'] / (1 + ((1/new_param_dict['k3']) * p1)**new_param_dict['n3'])) + new_param_dict['g3']\n",
    "        dp3dt = (new_param_dict['b3']*m3) - (new_param_dict['dp3']*p3)\n",
    "\n",
    "        return [dm1dt, dp1dt, dm2dt, dp2dt, dm3dt, dp3dt]\n",
    "\n",
    "    def solve_ode(theta, t):\n",
    "        initial_conditions = np.array([0, 2, 0, 1, 0, 3], dtype=np.float32)\n",
    "        y = odeint(model, initial_conditions, t, args=(theta,))\n",
    "                 #raw output\n",
    "        return torch.tensor(y, dtype=torch.float32)\n",
    "    return solve_ode(theta, t)\n",
    "prior = utils.BoxUniform(\n",
    "    low=torch.tensor([10**-2,10**-2,10**-2]),\n",
    "    high=torch.tensor([250.,250.,250.]))\n",
    "true_params = tuple(param_dict[parameter] for parameter in headers)\n",
    "true_data = my_simulator(true_params)\n",
    "num_dim = len(true_params)\n",
    "\n",
    "#Embedding net RNN\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.gru = nn.GRU(input_size, hidden_size, batch_first=True) #batch_size of 100\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "                                                       #The middle value needs to be the length, in this case 1000, or input.size(0) (try with true_data)\n",
    "                                                        #1 is the number of layers\n",
    "                                                        #Actually prepare for sbi adds a batch_size, so x.shape is (1, 1000, 6)\n",
    "    def forward(self, x):\n",
    "        h = torch.zeros(1, x.size(0), self.hidden_size)\n",
    "        gru_out, hn = self.gru(\n",
    "            x, h)\n",
    "        output = self.linear(gru_out[:,-1, :])\n",
    "        return output\n",
    "\n",
    "# Example usage\n",
    "input_size = 6 #Needs to be the same as input.size(-1)\n",
    "output_size = 25\n",
    "hidden_size = 100\n",
    "embedding_net = RNN(input_size, hidden_size, output_size)\n",
    "\n",
    "\n",
    "# Actual SNPE\n",
    "num_rounds = 2\n",
    "simulator_wrapper, prior = prepare_for_sbi(my_simulator, prior)\n",
    "\n",
    "\n",
    "# We define the neural network (neural density estimator), specifying the embedding net. In this case we use a mixture density network.\n",
    "neural_posterior = utils.posterior_nn(\n",
    "    model=\"maf\", embedding_net=embedding_net, hidden_features=50, num_transforms=3)\n",
    "\n",
    "# Setup the inference procedure with the SNPE-C (Greenberg et al, 2019)\n",
    "inference = SNPE(prior=prior, density_estimator=neural_posterior)\n",
    "\n",
    "posteriors = []\n",
    "proposal = prior\n",
    "\n",
    "num_simulations = 100\n",
    "simulation_batch_size = 15\n",
    "\n",
    "for _ in range(num_rounds):\n",
    "    theta, x = simulate_for_sbi(simulator_wrapper, proposal, num_simulations=num_simulations, simulation_batch_size=simulation_batch_size, num_workers=num_workers)\n",
    "    density_estimator = inference.append_simulations(\n",
    "        theta, x, proposal=proposal\n",
    "    ).train()\n",
    "    posterior = inference.build_posterior(density_estimator, sample_with=\"mcmc\")\n",
    "    posteriors.append(posterior)\n",
    "    proposal = posterior.set_default_x(true_data)\n",
    "\n",
    "posterior_samples_RNN = posterior.sample((100,), x=true_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0387cb6681a54506bf83c75a3d938cb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d36508b1d84a4a7b83110d552388915e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "posterior_samples_RNN = posterior.sample((100,), x=true_data)\n",
    "_ = analysis.pairplot(\n",
    "    posterior_samples_RNN, limits=[[-100, 300], [-100, 300], [-100, 300]], figsize=(6, 6) #It should be close to 247, but since this is a toy example we are not expecting it to work (just checking it runs).\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now bigger simulation 5 rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual SNPE\n",
    "embedding_net_custom = SummaryNet()\n",
    "num_rounds = 5\n",
    "simulator_wrapper, prior = prepare_for_sbi(simulator, prior)\n",
    "\n",
    "\n",
    "# We define the neural network (neural density estimator), specifying the embedding net. In this case we use a mixture density network.\n",
    "neural_posterior = utils.posterior_nn(\n",
    "    model=\"maf\", embedding_net=embedding_net_custom, hidden_features=50, num_transforms=3)\n",
    "\n",
    "# Setup the inference procedure with the SNPE-C (Greenberg et al, 2019)\n",
    "inference = SNPE(prior=prior, density_estimator=neural_posterior)\n",
    "\n",
    "posteriors = []\n",
    "proposal = prior\n",
    "\n",
    "num_simulations = 3000\n",
    "simulation_batch_size = 400\n",
    "\n",
    "for _ in range(num_rounds):\n",
    "    theta, x = simulate_for_sbi(simulator_wrapper, proposal, num_simulations=num_simulations, simulation_batch_size=simulation_batch_size, num_workers=num_workers)\n",
    "    density_estimator = inference.append_simulations(\n",
    "        theta, x, proposal=proposal\n",
    "    ).train()\n",
    "    posterior = inference.build_posterior(density_estimator)\n",
    "    posteriors.append(posterior)\n",
    "    proposal = posterior.set_default_x(true_data)\n",
    "\n",
    "posterior_samples_RNN = posterior.sample((50000,), x=true_data)\n",
    "_ = analysis.pairplot(\n",
    "    posterior_samples_RNN, limits=[[-100, 300], [-100, 300], [-100, 300]], figsize=(6, 6) #It should be close to 247, but since this is a toy example we are not expecting it to work (just checking it runs).\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now same but for 6 parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import odeint\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sbi.inference import SNPE, prepare_for_sbi, simulate_for_sbi\n",
    "from sbi import utils as utils\n",
    "from sbi import analysis as analysis\n",
    "from sbi.inference.base import infer\n",
    "import numpy as np\n",
    "\n",
    "# Old simulator without loops...\n",
    "def model(variables, t, params):\n",
    "\n",
    "    m1, p1, m2, p2, m3, p3 = variables\n",
    "    k1,k2,k3,a1,a2,a3=params #only 3 ks are parameters to infer\n",
    "    g1 = g2 = g3 = 0.024884149937163258\n",
    "    n1 = n2 = n3 = 5\n",
    "    b1 = b2 = b3 = 33.82307682700831\n",
    "    dm1 = dm2 = dm3 = 1.143402097500176\n",
    "    dp1 = dp2 = dp3 = 0.7833664565550977\n",
    "\n",
    "    dm1dt = -dm1 * m1 + (a1 / (1 + ((1/k1) * p2) ** n1)) + g1\n",
    "    dp1dt = (b1 * m1) - (dp1 * p1)\n",
    "    dm2dt = -dm2 * m2 + (a2 / (1 + ((1/k2) * p3) ** n2)) + g2\n",
    "    dp2dt = (b2 * m2) - (dp2 * p2)\n",
    "    dm3dt = -dm3 * m3 + (a3 / (1 + ((1/k3) * p1) ** n3)) + g3\n",
    "    dp3dt = (b3 * m3)-(dp3 * p3)\n",
    "    \n",
    "    return [dm1dt, dp1dt, dm2dt, dp2dt, dm3dt, dp3dt]\n",
    "\n",
    "# Initial conditions\n",
    "true_params = torch.tensor([\n",
    "    246.96291990024542, 246.96291990024542, 246.96291990024542,\n",
    "    24.78485282457379, 24.78485282457379, 24.78485282457379]).unsqueeze(0)\n",
    "num_timesteps = 100\n",
    "num_trajectories = 6\n",
    "y0 = np.array([0, 1, 0, 3, 0, 2])\n",
    "t = np.linspace(0, 100, num_timesteps)\n",
    "\n",
    "def simulator(parameter_set):\n",
    "    full_tensor = torch.zeros((num_trajectories * num_timesteps)).unsqueeze(0)\n",
    "    if len(parameter_set) == 1:\n",
    "        for params in parameter_set:\n",
    "            y = odeint(model, y0, t, args=(params,))\n",
    "            y_transposed = y.T\n",
    "            concatenated_trajectories = y_transposed.flatten()\n",
    "            yt = torch.tensor(concatenated_trajectories)\n",
    "            final_tensor = yt.unsqueeze(0).unsqueeze(-1)\n",
    "            return final_tensor\n",
    "    else:\n",
    "        for params in parameter_set:\n",
    "            y = odeint(model, y0, t, args=(params,))\n",
    "            y_transposed = y.T\n",
    "            concatenated_trajectories = y_transposed.flatten()\n",
    "            yt = torch.tensor(concatenated_trajectories)\n",
    "            true_tensor = yt.unsqueeze(0)\n",
    "            full_tensor = torch.cat((full_tensor, true_tensor), dim=0)\n",
    "        n_sims = full_tensor.size(0)\n",
    "        output_tensor = full_tensor[1:n_sims]\n",
    "        out = output_tensor.unsqueeze(-1)\n",
    "        return out\n",
    "    \n",
    "prior = utils.BoxUniform(\n",
    "    low=torch.tensor([10**-2,10**-2,10**-2,20.,20.,20.]),\n",
    "    high=torch.tensor([250.,250.,250.,40.,40.,40.]), device=device)\n",
    "\n",
    "true_data = simulator(true_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual SNPE\n",
    "num_rounds = 2\n",
    "simulator_wrapper, prior = prepare_for_sbi(simulator, prior)\n",
    "\n",
    "\n",
    "# We define the neural network (neural density estimator), specifying the embedding net. In this case we use a mixture density network.\n",
    "neural_posterior = utils.posterior_nn(\n",
    "    model=\"maf\", embedding_net=embedding_net_custom, hidden_features=50, num_transforms=3)\n",
    "\n",
    "# Setup the inference procedure with the SNPE-C (Greenberg et al, 2019)\n",
    "inference = SNPE(prior=prior, density_estimator=neural_posterior)\n",
    "\n",
    "posteriors = []\n",
    "proposal = prior\n",
    "\n",
    "num_simulations = 3000\n",
    "simulation_batch_size = 400\n",
    "\n",
    "for _ in range(num_rounds):\n",
    "    theta, x = simulate_for_sbi(simulator_wrapper, proposal, num_simulations=num_simulations, simulation_batch_size=simulation_batch_size, num_workers=num_workers)\n",
    "    density_estimator = inference.append_simulations(\n",
    "        theta, x, proposal=proposal\n",
    "    ).train()\n",
    "    posterior = inference.build_posterior(density_estimator)\n",
    "    posteriors.append(posterior)\n",
    "    proposal = posterior.set_default_x(true_data)\n",
    "\n",
    "posterior_samples_RNN = posterior.sample((50000,), x=true_data)\n",
    "_ = analysis.pairplot(\n",
    "    posterior_samples_RNN, limits=[[-100, 300], [-100, 300], [-100, 300]], figsize=(6, 6) #It should be close to 247, but since this is a toy example we are not expecting it to work (just checking it runs).\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now bigger simulation 5 rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual SNPE\n",
    "embedding_net_custom = SummaryNet()\n",
    "num_rounds = 5\n",
    "simulator_wrapper, prior = prepare_for_sbi(simulator, prior)\n",
    "\n",
    "\n",
    "# We define the neural network (neural density estimator), specifying the embedding net. In this case we use a mixture density network.\n",
    "neural_posterior = utils.posterior_nn(\n",
    "    model=\"maf\", embedding_net=embedding_net_custom, hidden_features=50, num_transforms=3)\n",
    "\n",
    "# Setup the inference procedure with the SNPE-C (Greenberg et al, 2019)\n",
    "inference = SNPE(prior=prior, density_estimator=neural_posterior)\n",
    "\n",
    "posteriors = []\n",
    "proposal = prior\n",
    "\n",
    "num_simulations = 3000\n",
    "simulation_batch_size = 400\n",
    "\n",
    "for _ in range(num_rounds):\n",
    "    theta, x = simulate_for_sbi(simulator_wrapper, proposal, num_simulations=num_simulations, simulation_batch_size=simulation_batch_size, num_workers=num_workers)\n",
    "    density_estimator = inference.append_simulations(\n",
    "        theta, x, proposal=proposal\n",
    "    ).train()\n",
    "    posterior = inference.build_posterior(density_estimator)\n",
    "    posteriors.append(posterior)\n",
    "    proposal = posterior.set_default_x(true_data)\n",
    "\n",
    "posterior_samples_RNN = posterior.sample((50000,), x=true_data)\n",
    "_ = analysis.pairplot(\n",
    "    posterior_samples_RNN, limits=[[-100, 300], [-100, 300], [-100, 300]], figsize=(6, 6) #It should be close to 247, but since this is a toy example we are not expecting it to work (just checking it runs).\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
