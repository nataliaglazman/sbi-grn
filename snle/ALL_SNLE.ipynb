{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1f107ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import math\n",
    "from math import ceil\n",
    "import random\n",
    "import peakutils\n",
    "import pandas as pd\n",
    "import contextlib\n",
    "import torch\n",
    "import sys\n",
    "import sbi\n",
    "import numpy as np\n",
    "from numpy import fft, ndarray\n",
    "from scipy.integrate import odeint\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "from pyro.infer.mcmc.api import MCMC\n",
    "from warnings import warn\n",
    "from torch import Tensor, split, randint, cat\n",
    "from typing import Any, Callable, Optional, Tuple, Union, Dict\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "from tqdm.auto import tqdm, trange\n",
    "from pyro.infer.mcmc import HMC, NUTS\n",
    "from sbi.inference import prepare_for_sbi, SNLE\n",
    "from sbi import utils as utils\n",
    "from sbi import analysis as analysis\n",
    "from sbi.types import Shape, TorchTransform\n",
    "from sbi.utils.get_nn_models import (likelihood_nn,)\n",
    "from sbi.samplers.mcmc import SliceSamplerVectorized\n",
    "from sbi.samplers.mcmc.slice_numpy import MCMCSampler\n",
    "from sbi.utils import tensor2numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "2b09aff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_all_backends(seed: Optional[Union[int, Tensor]] = None) -> None:\n",
    "    if seed is None:\n",
    "        seed = int(torch.randint(10_000_000, size=(1,)))\n",
    "    else:\n",
    "        # Cast Tensor to int (required by math.random since Python 3.11)\n",
    "        seed = int(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True # type: ignore\n",
    "    torch.backends.cudnn.benchmark = False # type: ignore\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def tqdm_joblib(tqdm_object):\n",
    "    def tqdm_print_progress(self):\n",
    "        if self.n_completed_tasks > tqdm_object.n:\n",
    "            n_completed = self.n_completed_tasks - tqdm_object.n\n",
    "            tqdm_object.update(n=n_completed)\n",
    "    \n",
    "    original_print_progress = joblib.parallel.Parallel.print_progress\n",
    "    joblib.parallel.Parallel.print_progress = tqdm_print_progress\n",
    "    \n",
    "    try:\n",
    "        yield tqdm_object\n",
    "    finally:\n",
    "        joblib.parallel.Parallel.print_progress = original_print_progress\n",
    "        tqdm_object.close()\n",
    "\n",
    "class SliceSampler(MCMCSampler):\n",
    "    def __init__(self, x, lp_f, max_width=float(\"inf\"), init_width: Union[float, np.ndarray] = 0.05, thin=None, tuning: int = 50, verbose: bool = False,):\n",
    "        MCMCSampler.__init__(self, x, lp_f, thin, verbose=verbose)\n",
    "        self.max_width = max_width\n",
    "        self.init_width = init_width\n",
    "        self.width = None\n",
    "        self.tuning = tuning\n",
    "        \n",
    "    def _tune_bracket_width(self, rng):\n",
    "        order = list(range(self.n_dims))\n",
    "        x = self.x.copy()\n",
    "\n",
    "        self.width = np.full(self.n_dims, self.init_width)\n",
    "\n",
    "        tbar = trange(self.tuning, miniters=2, disable=not self.verbose)\n",
    "        tbar.set_description(\"Tuning bracket width...\")\n",
    "        for n in tbar:\n",
    "            # for n in range(int(self.tuning)):\n",
    "            rng.shuffle(order)\n",
    "            for i in range(self.n_dims):\n",
    "                x[i], wi = self._sample_from_conditional(i, x[i], rng)\n",
    "                self.width[i] += (wi - self.width[i]) / (n + 1)\n",
    "\n",
    "    def _sample_from_conditional(self, i: int, cxi, rng):\n",
    "        assert self.width is not None, \"Chain not initialized.\"\n",
    "\n",
    "        # conditional log prob\n",
    "        Li = lambda t: self.lp_f(np.concatenate([self.x[:i], [t], self.x[i + 1 :]]))\n",
    "        wi = self.width[i]\n",
    "\n",
    "        # sample a slice uniformly\n",
    "        logu = Li(cxi) + np.log(1.0 - rng.rand())\n",
    "\n",
    "        # position the bracket randomly around the current sample\n",
    "        lx = cxi - wi * rng.rand()\n",
    "        ux = lx + wi\n",
    "        \n",
    "        # find lower bracket end\n",
    "        while Li(lx) >= logu and cxi - lx < self.max_width:\n",
    "            lx -= wi\n",
    "\n",
    "        # find upper bracket end\n",
    "        while Li(ux) >= logu and ux - cxi < self.max_width:\n",
    "            ux += wi\n",
    "\n",
    "        # sample uniformly from bracket\n",
    "        xi = (ux - lx) * rng.rand() + lx\n",
    "\n",
    "        # if outside slice, reject sample and shrink bracket\n",
    "        while Li(xi) < logu:\n",
    "            if xi < cxi:\n",
    "                lx = xi\n",
    "            else:\n",
    "                ux = xi\n",
    "            xi = (ux - lx) * rng.rand() + lx\n",
    "       \n",
    "        return xi, ux - lx\n",
    "      \n",
    "def run_fun(SliceSamplerSerial, num_samples, inits, seed, log_prob_fn: Callable, thin: Optional[int] = None, tuning: int = 50, verbose: bool = True, init_width: Union[float, np.ndarray] = 0.01,\n",
    "            max_width: float = float(\"inf\"), num_workers: int = 1, rng=np.random, show_info: bool = False, logger=sys.stdout) -> np.ndarray:\n",
    "    np.random.seed(seed)\n",
    "    posterior_sampler = SliceSampler(inits, lp_f=log_prob_fn, max_width=max_width, init_width=init_width, thin=thin, tuning=tuning, verbose=num_workers == 1 and verbose,)\n",
    "    \n",
    "    assert num_samples >= 0, \"number of samples can't be negative\"\n",
    "\n",
    "    order = list(range(posterior_sampler.n_dims))\n",
    "    L_trace = []\n",
    "    samples = np.empty([int(num_samples), int(posterior_sampler.n_dims)])\n",
    "    logger = open(os.devnull, \"w\") if logger is None else logger\n",
    "\n",
    "    if posterior_sampler.width is None:\n",
    "        # logger.write('tuning bracket width...\\n')\n",
    "        posterior_sampler._tune_bracket_width(rng)\n",
    "\n",
    "    tbar = trange(int(num_samples), miniters=10, disable=not posterior_sampler.verbose)\n",
    "    tbar.set_description(\"Generating samples\")\n",
    "    for n in tbar:\n",
    "        # for n in range(int(n_samples)):\n",
    "        for _ in range(posterior_sampler.thin):\n",
    "            rng.shuffle(order)\n",
    "\n",
    "            for i in order:\n",
    "                posterior_sampler.x[i], _ = posterior_sampler._sample_from_conditional(i, posterior_sampler.x[i], rng)\n",
    "\n",
    "        samples[n] = posterior_sampler.x.copy()\n",
    "\n",
    "        posterior_sampler.L = posterior_sampler.lp_f(posterior_sampler.x)\n",
    "        # logger.write('sample = {0}, log prob = {1:.2}\\n'.format(n+1, self.L))\n",
    "\n",
    "        if show_info:\n",
    "            L_trace.append(posterior_sampler.L)\n",
    "\n",
    "    # show trace plot\n",
    "    if show_info:\n",
    "        fig, ax = plt.subplots(1, 1)\n",
    "        ax.plot(L_trace)\n",
    "        ax.set_ylabel(\"log probability\")\n",
    "        ax.set_xlabel(\"samples\")\n",
    "        plt.show(block=False)\n",
    "\n",
    "    return samples\n",
    "\n",
    "def run(SliceSamplerSerial, log_prob_fn: Callable, num_samples: int, init_params: np.ndarray, num_chains: int = 1, thin: Optional[int] = None, verbose: bool = True, num_workers: int = 1,) -> np.ndarray:\n",
    "    num_chains , dim_samples = init_params.shape\n",
    "    # Generate seeds for workers from current random state.\n",
    "    seeds = torch.randint(high=1_000_000, size=(num_chains,))\n",
    "    for seed in seeds:\n",
    "        seed_all_backends(seed)\n",
    "    with tqdm_joblib(tqdm(range(num_chains), disable=not verbose, desc=f\"\"\"Running {num_chains} MCMC chains with {num_workers} worker{\"s\" if num_workers>1 else \"\"}.\"\"\", total=num_chains,)):\n",
    "        all_samples = Parallel(n_jobs=num_workers)(delayed(run_fun)(SliceSamplerSerial, num_samples, initial_params_batch, seed, log_prob_fn)for initial_params_batch, seed in zip(init_params, seeds))\n",
    "    samples = np.stack(all_samples).astype(np.float32)\n",
    "    samples = samples.reshape(num_chains, -1, dim_samples)  # chains, samples, dim\n",
    "    samples = samples[:, :: thin, :]  # thin chains\n",
    "\n",
    "    # save samples\n",
    "    return samples\n",
    "\n",
    "class SliceSamplerSerial:\n",
    "    def __init__(self, log_prob_fn: Callable, init_params: np.ndarray, num_chains: int = 1, thin: Optional[int] = None, tuning: int = 50, verbose: bool = True, init_width: Union[float, np.ndarray] = 0.01, max_width: float = float(\"inf\"), num_workers: int = 1,):\n",
    "        self._log_prob_fn = log_prob_fn\n",
    "        self.x = init_params\n",
    "        self.num_chains = num_chains\n",
    "        self.thin = thin\n",
    "        self.tuning = tuning\n",
    "        self.verbose = verbose\n",
    "        self.init_width = init_width\n",
    "        self.max_width = max_width\n",
    "        self.n_dims = self.x.size\n",
    "        self.num_workers = num_workers\n",
    "        self._samples = None\n",
    "\n",
    "    def get_samples(self, num_samples: Optional[int] = None, group_by_chain: bool = True) -> np.ndarray:\n",
    "        if self._samples is None:\n",
    "            raise ValueError(\"No samples found from MCMC run.\")\n",
    "        # if not grouped by chain, flatten samples into (all_samples, dim_params)\n",
    "        if not group_by_chain:\n",
    "            samples = self._samples.reshape(-1, self._samples.shape[2])\n",
    "        else:\n",
    "            samples = self._samples\n",
    "\n",
    "        # if not specified return all samples\n",
    "        if num_samples is None:\n",
    "            return samples\n",
    "        # otherwise return last num_samples (for each chain when grouped).\n",
    "        elif group_by_chain:\n",
    "            return samples[:, -num_samples:, :]\n",
    "        else:\n",
    "            return samples[-num_samples:, :]\n",
    "\n",
    "##############################################################################################################################\n",
    "        \n",
    "def _maybe_use_dict_entry(default: Any, key: str, dict_to_check: Dict) -> Any:\n",
    "    attribute = default if key not in dict_to_check.keys() else dict_to_check[key]\n",
    "    return attribute\n",
    "\n",
    "def _get_initial_params(proposal, init_strategy: str, num_chains: int, num_workers: int, show_progress_bars: bool, **kwargs,) -> Tensor: \n",
    "    # Build init function\n",
    "    init_fn = proposal._build_mcmc_init_fn(proposal.proposal, proposal.potential_fn, transform=proposal.theta_transform, init_strategy=init_strategy, **kwargs,)\n",
    "\n",
    "    # Parallelize inits for resampling only.\n",
    "    if num_workers > 1 and (init_strategy == \"resample\" or init_strategy == \"sir\"):\n",
    "        def seeded_init_fn(seed):\n",
    "            torch.manual_seed(seed)\n",
    "            return init_fn()\n",
    "\n",
    "        seeds = torch.randint(high=10_000_000, size=(num_chains,))\n",
    "\n",
    "        # Generate initial params parallelized over num_workers.\n",
    "        with tqdm_joblib(tqdm(range(num_chains), disable=not show_progress_bars, desc=f\"\"\"Generating {num_chains} MCMC inits with {num_workers} workers.\"\"\", total=num_chains,)):\n",
    "            initial_params = torch.cat(Parallel(n_jobs=num_workers)(delayed(seeded_init_fn)(seed) for seed in seeds))\n",
    "    else:\n",
    "        initial_params = torch.cat([init_fn() for _ in range(num_chains)])\n",
    "    return initial_params\n",
    "    \n",
    "def _slice_np_mcmc(proposal, num_samples: int, potential_function: Callable, initial_params: Tensor, thin: int, warmup_steps: int, vectorized: bool = False, num_workers: int = 1, init_width: Union[float, ndarray] = 0.01, show_progress_bars: bool = True,) -> Tensor:\n",
    "    num_chains, dim_samples = initial_params.shape\n",
    "        \n",
    "    if not vectorized:\n",
    "        SliceSamplerMultiChain = SliceSamplerSerial\n",
    "    else:\n",
    "        SliceSamplerMultiChain = SliceSamplerVectorized\n",
    "\n",
    "    posterior_sampler = SliceSamplerMultiChain(init_params=tensor2numpy(initial_params), log_prob_fn=potential_function, num_chains=num_chains, thin=thin, verbose=show_progress_bars, num_workers=num_workers, init_width=init_width,)\n",
    "    warmup_ = warmup_steps * thin\n",
    "    num_samples_ = ceil((num_samples * thin) / num_chains)\n",
    "    # Run mcmc including warmup\n",
    "    samples = run(posterior_sampler, log_prob_fn=potential_function, num_samples = (warmup_ + num_samples_), init_params = tensor2numpy(initial_params))\n",
    "    samples = samples[:, warmup_steps:, :]  # discard warmup steps\n",
    "    samples = torch.from_numpy(samples)  # chains x samples x dim\n",
    "\n",
    "    # Save posterior sampler.\n",
    "    proposal._posterior_sampler = posterior_sampler\n",
    "\n",
    "    # Save sample as potential next init (if init_strategy == 'latest_sample').\n",
    "    proposal._mcmc_init_params = samples[:, -1, :].reshape(num_chains, dim_samples)\n",
    "\n",
    "    # Collect samples from all chains.\n",
    "    samples = samples.reshape(-1, dim_samples)[:num_samples, :]\n",
    "    assert samples.shape[0] == num_samples\n",
    "    return samples.type(torch.float32).to(proposal._device)\n",
    "\n",
    "def sample_my_fun(proposal, sample_shape: Shape = torch.Size(), x: Optional[Tensor] = None, method: Optional[str] = None, thin: Optional[int] = None, warmup_steps: Optional[int] = None, num_chains: Optional[int] = None, init_strategy: Optional[str] = None, init_strategy_parameters: Optional[Dict[str, Any]] = None,\n",
    "                   init_strategy_num_candidates: Optional[int] = None, mcmc_parameters: Dict = {}, mcmc_method: Optional[str] = None, sample_with: Optional[str] = None, num_workers: Optional[int] = None, show_progress_bars: bool = True,) -> Tensor:\n",
    "    \n",
    "    proposal.potential_fn.set_x(proposal._x_else_default_x(x))\n",
    "\n",
    "    # Replace arguments that were not passed with their default.\n",
    "    method = proposal.method if method is None else method\n",
    "    thin = proposal.thin if thin is None else thin\n",
    "    warmup_steps = proposal.warmup_steps if warmup_steps is None else warmup_steps\n",
    "    num_chains = proposal.num_chains if num_chains is None else num_chains\n",
    "    init_strategy = proposal.init_strategy if init_strategy is None else init_strategy\n",
    "    num_workers = proposal.num_workers if num_workers is None else num_workers\n",
    "    init_strategy_parameters = (proposal.init_strategy_parameters if init_strategy_parameters is None else init_strategy_parameters)\n",
    "\n",
    "    if init_strategy_num_candidates is not None:\n",
    "        warn(\"\"\"Passing `init_strategy_num_candidates` is deprecated as of sbi v0.19.0. Instead, use e.g.,`init_strategy_parameters={\"num_candidate_samples\": 1000}`\"\"\")\n",
    "        proposal.init_strategy_parameters[\"num_candidate_samples\"] = (init_strategy_num_candidates)\n",
    "    if sample_with is not None:\n",
    "        raise ValueError(f\"You set `sample_with={sample_with}`. As of sbi v0.18.0, setting `sample_with` is no longer supported. You have to rerun `.build_posterior(sample_with={sample_with}).`\")\n",
    "    if mcmc_method is not None:\n",
    "        warn(\"You passed `mcmc_method` to `.sample()`. As of sbi v0.18.0, this is deprecated and will be removed in a future release. Use `method` instead of `mcmc_method`.\")\n",
    "        method = mcmc_method\n",
    "    if mcmc_parameters:\n",
    "        warn(\"You passed `mcmc_parameters` to `.sample()`. As of sbi v0.18.0, this is deprecated and will be removed in a future release. Instead, pass the variable to `.sample()` directly, e.g. `posterior.sample((1,), num_chains=5)`.\")\n",
    "    # The following lines are only for backwards compatibility with sbi v0.17.2 or older.\n",
    "    m_p = mcmc_parameters  # define to shorten the variable name\n",
    "    method = _maybe_use_dict_entry(method, \"mcmc_method\", m_p)\n",
    "    thin = _maybe_use_dict_entry(thin, \"thin\", m_p)\n",
    "    warmup_steps = _maybe_use_dict_entry(warmup_steps, \"warmup_steps\", m_p)\n",
    "    num_chains = _maybe_use_dict_entry(num_chains, \"num_chains\", m_p)\n",
    "    init_strategy = _maybe_use_dict_entry(init_strategy, \"init_strategy\", m_p)\n",
    "    proposal.potential_ = proposal._prepare_potential(method)  # type: ignore\n",
    "\n",
    "    initial_params = _get_initial_params(proposal, init_strategy, num_chains, num_workers, show_progress_bars, **init_strategy_parameters,)\n",
    "    num_samples = torch.Size(sample_shape).numel()\n",
    "\n",
    "    track_gradients = method in (\"hmc\", \"nuts\")\n",
    "    with torch.set_grad_enabled(track_gradients):\n",
    "        if method in (\"slice_np\", \"slice_np_vectorized\"):\n",
    "            transformed_samples = _slice_np_mcmc(proposal, num_samples=num_samples, potential_function=proposal.potential_, initial_params=initial_params, thin=thin, warmup_steps=warmup_steps, vectorized=(method == \"slice_np_vectorized\"), num_workers=num_workers, show_progress_bars=show_progress_bars,)\n",
    "        elif method in (\"hmc\", \"nuts\", \"slice\"):\n",
    "            transformed_samples = _pyro_mcmc(proposal, num_samples=num_samples, potential_function=proposal.potential_, initial_params=initial_params, mcmc_method=method, thin=thin, warmup_steps=warmup_steps, num_chains=num_chains, show_progress_bars=show_progress_bars,)\n",
    "        else:\n",
    "            raise NameError\n",
    "\n",
    "    samples = proposal.theta_transform.inv(transformed_samples)\n",
    "\n",
    "    return samples.reshape((*sample_shape, -1))  # type: ignore\n",
    "\n",
    "#######################################################################################################################################\n",
    "\n",
    "def simulator_seeded(simulator: Callable, theta: Tensor, seed: int) -> Tensor:\n",
    "    import torch\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    with torch.random.fork_rng(devices=[]):\n",
    "        torch.manual_seed(seed)\n",
    "        return simulator(theta)\n",
    "\n",
    "def simulate_in_batches(simulator: Callable, theta: Tensor, sim_batch_size: int = 1, num_workers: int = 1 , seed: Optional[int] = None, show_progress_bars: bool = True, ) -> Tensor:\n",
    "    num_sims, *_ = theta.shape\n",
    "    seed_all_backends(seed)\n",
    "    if num_sims == 0:\n",
    "        x = torch.tensor([])\n",
    "    elif sim_batch_size is not None and sim_batch_size < num_sims:\n",
    "        batches = split(theta, sim_batch_size, dim=0)\n",
    "        \n",
    "        if num_workers != 1:\n",
    "            batch_seeds = randint(high=1_000_000, size=(len(batches),))\n",
    "            with tqdm_joblib(tqdm(batches, disable=not show_progress_bars, total = len(batches), desc=f\"Running {num_sims} simulations in {len(batches)} batches ({num_workers} cores)\",)) as _:\n",
    "                simulation_outputs = Parallel(n_jobs=num_workers)(delayed(simulator_seeded)(simulator, batch, batch_seed) for batch, batch_seed in zip(batches, batch_seeds))\n",
    "        else:\n",
    "            pbar = tqdm(total=num_sims, disable=not show_progress_bars, desc=f\"Running {num_sims} simulations.\", )\n",
    "            with pbar:\n",
    "                simulation_outputs = []\n",
    "                for batch in batches:\n",
    "                    simulation_outputs.append(simulator_seeded(simulator, batch, seed))\n",
    "                    pbar.update(sim_batch_size)\n",
    "        x = cat(simulation_outputs, dim=0)\n",
    "    else:\n",
    "        x = simulator(theta)\n",
    "    return x\n",
    "\n",
    "def simulate_for_sbi(round_idx: int, simulator: Callable, proposal: Any, num_simulations: int, num_workers: int = 1, simulation_batch_size: int = 1, seed: Optional[int] = None, show_progress_bar: bool = True)-> Tuple[Tensor, Tensor]:\n",
    "    if round_idx == 0:\n",
    "        theta = proposal.sample((num_simulations,))\n",
    "    else:\n",
    "        theta = sample_my_fun(proposal, (num_simulations,), num_workers = num_workers, num_chains = 4) # because only in first round proposal is boxuniform, then it is mcmcposterior object\n",
    "    \n",
    "    x = simulate_in_batches(simulator=simulator, theta=theta, sim_batch_size=simulation_batch_size, num_workers=num_workers, seed=seed, show_progress_bars=show_progress_bar)\n",
    "    \n",
    "    return theta, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "625fb39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNLE FOR 3 PARAMETERS (k1, k2, k3), 10 ROUNDS, EACH OF 1500 SIMULATIONS\n",
      "Round 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running 1500 simulations in 188 batches (8 cores):   4%|‚ñç         | 8/188 [00:53<20:06,  6.70s/it]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[127], line 86\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_rounds):\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRound \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 86\u001b[0m     theta, x \u001b[38;5;241m=\u001b[39m \u001b[43msimulate_for_sbi\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msimulator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproposal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_simulations\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_simulations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msimulation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msimulation_batch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m     density_estimator \u001b[38;5;241m=\u001b[39m inference\u001b[38;5;241m.\u001b[39mappend_simulations(theta, x)\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     88\u001b[0m     posterior \u001b[38;5;241m=\u001b[39m inference\u001b[38;5;241m.\u001b[39mbuild_posterior(density_estimator)\n",
      "Cell \u001b[0;32mIn[126], line 320\u001b[0m, in \u001b[0;36msimulate_for_sbi\u001b[0;34m(round_idx, simulator, proposal, num_simulations, num_workers, simulation_batch_size, seed, show_progress_bar)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    318\u001b[0m     theta \u001b[38;5;241m=\u001b[39m sample_my_fun(proposal, (num_simulations,), num_workers \u001b[38;5;241m=\u001b[39m num_workers, num_chains \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m) \u001b[38;5;66;03m# because only in first round proposal is boxuniform, then it is mcmcposterior object\u001b[39;00m\n\u001b[0;32m--> 320\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43msimulate_in_batches\u001b[49m\u001b[43m(\u001b[49m\u001b[43msimulator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msimulator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msim_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msimulation_batch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m theta, x\n",
      "Cell \u001b[0;32mIn[126], line 301\u001b[0m, in \u001b[0;36msimulate_in_batches\u001b[0;34m(simulator, theta, sim_batch_size, num_workers, seed, show_progress_bars)\u001b[0m\n\u001b[1;32m    299\u001b[0m     batch_seeds \u001b[38;5;241m=\u001b[39m randint(high\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1_000_000\u001b[39m, size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mlen\u001b[39m(batches),))\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tqdm_joblib(tqdm(batches, disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m show_progress_bars, total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batches), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_sims\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m simulations in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(batches)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m batches (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_workers\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cores)\u001b[39m\u001b[38;5;124m\"\u001b[39m,)) \u001b[38;5;28;01mas\u001b[39;00m _:\n\u001b[0;32m--> 301\u001b[0m         simulation_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_workers\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43msimulator_seeded\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43msimulator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_seed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_seed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_seeds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    303\u001b[0m     pbar \u001b[38;5;241m=\u001b[39m tqdm(total\u001b[38;5;241m=\u001b[39mnum_sims, disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m show_progress_bars, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_sims\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m simulations.\u001b[39m\u001b[38;5;124m\"\u001b[39m, )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/joblib/parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1707\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "headers = [\"k1\", \"k2\", \"k3\"]          # parameters to be inferred\n",
    "num_timesteps = 100\n",
    "\n",
    "# FOR SNLE\n",
    "prior_min = 0.01                        # same for all parameters\n",
    "prior_max = 250                        # same for all parameters\n",
    "# num_rounds = 3                        # how many rounds of SNLE\n",
    "# num_simulations = 3000               # in each round\n",
    "\n",
    "# 1 hyperparameter_set = [num_rounds, num_simulations per round, simulation_batch_size, CPUs_to_use]\n",
    "hyperparameters =[[10, 1500, 20, 75], [5, 3000, 40, 75], [3, 5000, 100, 50]]\n",
    "\n",
    "# To simulate in batches, simulation_batch_size must not be None and simulation_batch_size < num_simulations\n",
    "# To parallelise, set number of CPUs to be used.\n",
    "# simulation_batch_size = 8\n",
    "#  # run os.cpu_count() to see number of available CPUs\n",
    "# CPUs_to_use = 50\n",
    "\n",
    "#################################################################################################################################\n",
    "\n",
    "# # FOR MCMC\n",
    "# num_iterations = 10_000 # total in all chains\n",
    "# interval_to_calculate_acceptance_rate = 100\n",
    "# burn_in_fraction = 0.3\n",
    "# num_chains = 4\n",
    "\n",
    "####################################################################################################################################\n",
    "\n",
    "\n",
    "t = np.linspace(0, 100, num_timesteps)\n",
    "\n",
    "param_dict = {'k1': 246.96291990024542, 'k2': 246.96291990024542, 'k3': 246.96291990024542, 'n1': 5, 'n2': 5, 'n3': 5, 'dm1': 1.143402097500176, 'dm2': 1.143402097500176, 'dm3': 1.143402097500176,\n",
    "              'dp1': 0.7833664565550977, 'dp2': 0.7833664565550977, 'dp3': 0.7833664565550977, 'a1': 24.78485282457379, 'a2': 24.78485282457379, 'a3': 24.78485282457379,\n",
    "              'g1': 0.024884149937163258, 'g2': 0.024884149937163258, 'g3': 0.024884149937163258, 'b1': 33.82307682700831, 'b2': 33.82307682700831, 'b3': 33.82307682700831}\n",
    "\n",
    "all_params = 'a1', 'a2', 'a3', 'g1', 'g2', 'g3', 'dm1', 'dm2', 'dm3', 'dp1', 'dp2', 'dp3', 'b1', 'b2', 'b3', 'n1', 'n2', 'n3', 'k1', 'k2', 'k3'\n",
    "new_param_dictx ={}\n",
    "for param in all_params:\n",
    "    if param not in headers:\n",
    "        new_param_dictx[param] = param_dict[param]\n",
    "    elif param in headers:\n",
    "        new_param_dictx[param] = param\n",
    "\n",
    "def my_simulator(theta):\n",
    "    def model(variables, t, new_param_dict):\n",
    "        m1, p1, m2, p2, m3, p3 = variables\n",
    "        \n",
    "        dm1dt = -new_param_dict['dm1']*m1 + (new_param_dict['a1'] / (1 + (p2/new_param_dict['k1'])**new_param_dict['n1'])) + new_param_dict['g1']\n",
    "        dp1dt = (new_param_dict['b1']*m1) - (new_param_dict['dp1']*p1)\n",
    "        dm2dt = -new_param_dict['dm2']*m2 + (new_param_dict['a2'] / (1 + (p3/new_param_dict['k2'])**new_param_dict['n2'])) + new_param_dict['g2']\n",
    "        dp2dt = (new_param_dict['b2']*m2) - (new_param_dict['dp2']*p2)\n",
    "        dm3dt = -new_param_dict['dm3']*m3 + (new_param_dict['a3'] / (1 + (p1/new_param_dict['k3'])**new_param_dict['n3'])) + new_param_dict['g3']\n",
    "        dp3dt = (new_param_dict['b3']*m3) - (new_param_dict['dp3']*p3)\n",
    "\n",
    "        return [dm1dt, dp1dt, dm2dt, dp2dt, dm3dt, dp3dt]\n",
    "\n",
    "    def solve_ode(theta, t, new_param_dict = new_param_dictx):\n",
    "        for i in range(len(headers)):\n",
    "            new_param_dict[headers[i]] = theta[i]\n",
    "\n",
    "        initial_conditions = np.array([0, 2, 0, 1, 0, 3], dtype=np.float32)\n",
    "        solution = odeint(model, initial_conditions, t, args=(new_param_dict,))\n",
    "        return torch.tensor(solution, dtype=torch.float32).flatten() # Flatten tensor to size [600]\n",
    "    return solve_ode(theta, t)\n",
    "\n",
    "true_params = tuple(param_dict[parameter] for parameter in headers)\n",
    "true_solutions = my_simulator(true_params)\n",
    "\n",
    "#####################################################################################################################\n",
    "\n",
    "num_dim = len(true_params)\n",
    "prior = utils.BoxUniform(low=prior_min * torch.ones(num_dim), high=prior_max * torch.ones(num_dim))\n",
    "simulator, prior = prepare_for_sbi(my_simulator, prior)\n",
    "\n",
    "my_density_estimator = likelihood_nn(model=\"maf\", hidden_features=50, num_transforms=3)\n",
    "\n",
    "inference = SNLE(prior = prior, density_estimator = my_density_estimator) # Initialise inference\n",
    "posteriors = [] # Empty list to contain posterior after each round\n",
    "proposal = prior # For the first round proposal = prior, then updated (sequentiality)\n",
    "\n",
    "for hyperparameter_set in hyperparameters:\n",
    "    num_rounds, num_simulations, simulation_batch_size, num_workers = hyperparameter_set # num_workers = CPUs_to_use\n",
    "    print(f\"SNLE FOR {num_dim} PARAMETER{'S' if len(headers)>1 else ''} ({', '.join(headers)}), {num_rounds} ROUND{'S' if num_rounds>1 else ''}{', EACH' if num_rounds>1 else ''} OF {num_simulations} SIMULATIONS (using {num_workers} cores)\")\n",
    "    for _ in range(num_rounds):\n",
    "        print(f\"Round {_+1}\")\n",
    "        theta, x = simulate_for_sbi(_, simulator, proposal, num_simulations = num_simulations, simulation_batch_size = simulation_batch_size, num_workers = num_workers)\n",
    "        density_estimator = inference.append_simulations(theta, x).train()\n",
    "        posterior = inference.build_posterior(density_estimator)\n",
    "        posteriors.append(posterior)\n",
    "        proposal = posterior.set_default_x(true_solutions)\n",
    "        print(\"\\n\")\n",
    "\n",
    "    posterior_samples = sample_my_fun(posterior, (9975,), num_chains = 1) # sample to plot the posteriors\n",
    "\n",
    "    snle_data = pd.DataFrame(data=posterior_samples, columns=headers)\n",
    "    snle_data.to_csv(f'{num_dim}p-{num_rounds}*{num_simulations}.csv')\n",
    "\n",
    "    # Calculate quantiles of posterior samples\n",
    "    posterior_quantiles = np.percentile(posterior_samples, [1, 99], axis=0)\n",
    "\n",
    "    # Define custom limits slightly larger than the range of the central 98% of the posterior samples\n",
    "    custom_limits = [(posterior_quantiles[0][i] - 0.2 * (posterior_quantiles[1][i] - posterior_quantiles[0][i]), posterior_quantiles[1][i] + 0.2 * (posterior_quantiles[1][i] - posterior_quantiles[0][i])) for i in range(num_dim)]\n",
    "\n",
    "    # Plot pair plots with custom limits\n",
    "    _ = analysis.pairplot(posterior_samples, limits=custom_limits, figsize=(8, 8), labels=headers)\n",
    "\n",
    "    plt.savefig(f'SNLE-{num_dim}p-{num_rounds}*{num_simulations}-P_customlimits.png')\n",
    "\n",
    "    _ = analysis.pairplot(posterior_samples, limits=[[prior_min, prior_max]]*num_dim, figsize=(8, 8), labels=headers)\n",
    "\n",
    "    plt.savefig(f'SNLE-{num_dim}p-{num_rounds}*{num_simulations}-P_priorlimits.png')\n",
    "\n",
    "    variables = ['m1', 'p1', 'm2', 'p2', 'm3', 'p3']\n",
    "\n",
    "    raw_trajectories=np.zeros([len(posterior_samples), num_timesteps, len(variables)])\n",
    "\n",
    "    def simulate_sample(batch, seed):\n",
    "        np.random.seed(seed)\n",
    "        result = []\n",
    "        for i in range(len(batch)):\n",
    "            result.append(my_simulator(batch[i]).reshape(num_timesteps, len(variables)))\n",
    "        return result\n",
    "\n",
    "    # Use joblib to parallelize the simulation\n",
    "    batches = split(posterior_samples, int(len(posterior_samples)//num_workers), dim =0)\n",
    "\n",
    "    seeds = randint(high=1_000_000, size=(len(batches),))\n",
    "    with tqdm_joblib(tqdm(batches, total = len(batches), desc=f\"Running {len(posterior_samples)} simulations in {len(batches)} batches ({num_workers} cores)\",)) as _: \n",
    "        results = Parallel(n_jobs=num_workers)(delayed(simulate_sample)(batch, seed) for batch, seed in zip(batches, seeds))\n",
    "\n",
    "    index = 0\n",
    "    for i in range(len(results)):\n",
    "        for j in range(len(results[i])):\n",
    "            raw_trajectories[index] = results[i][j]\n",
    "            index += 1\n",
    "\n",
    "    tr = np.percentile(raw_trajectories, [2.5, 97.5], axis=0)\n",
    "\n",
    "    fig, ax=plt.subplots(3, 2, figsize=(30,18))\n",
    "    ax = ax.ravel()\n",
    "    col=[\"blue\",\"blue\"]\n",
    "    for i in range(6):\n",
    "        for j in range(2):\n",
    "            ax[i].plot(tr[j,:,i],alpha=0.4,linestyle='dotted',linewidth=1, color='black')\n",
    "        ax[i].plot(true_solutions.reshape(100, 6)[:,i],linewidth=1,color='black', label = 'true')\n",
    "        ax[i].fill_between(t, tr[0, :, i],tr[1, :, i], alpha=0.4, color='skyblue')\n",
    "        ax[i].legend()\n",
    "\n",
    "    plt.savefig(f'SNLE-{num_dim}p-{num_rounds}*{num_simulations}-T.png')"
   ]
  }
