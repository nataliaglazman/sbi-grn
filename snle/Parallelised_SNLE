# PART 1: Edited code from original sbi repos. Functions edited: simulate_for_sbi, and all the functions it contains.
Main changes: defined simulator_seeded globally rather than within simulate_in_batches function, and re-imported torch within simulator_seeded 
NO changes need to be made in this file

# PART 2: Essentially the unparallelised code with 2 extra arguments in the simulate_for_sbi line

##################################### PART 1 #########################################
import joblib
import contextlib
import random
import torch
import numpy as np

from torch import Tensor, split, randint, cat
from typing import Any, Callable, Optional, Tuple, Union
from joblib import Parallel, delayed
from tqdm import tqdm
from tqdm.auto import tqdm

def seed_all_backends(seed: Optional[Union[int, Tensor]] = None) -> None:
    if seed is None:
        seed = int(torch.randint(1_000_000, size=(1,)))
    else:
        # Cast Tensor to int (required by math.random since Python 3.11)
        seed = int(seed)

    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.backends.cudnn.deterministic = True # type: ignore
    torch.backends.cudnn.benchmark = False # type: ignore

def simulator_seeded(simulator: Callable, theta: Tensor, seed: int) -> Tensor:
    import torch
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    with torch.random.fork_rng(devices=[]):
        torch.manual_seed(seed)
        return simulator(theta)

def simulate_in_batches(simulator: Callable, theta: Tensor, sim_batch_size: int = 1, num_workers: int = 1,
                        seed: Optional[int] = None, show_progress_bars: bool = True, ) -> Tensor:

    num_sims, *_ = theta.shape
    seed_all_backends(seed)

    if num_sims == 0:
        x = torch.tensor([])
    elif sim_batch_size is not None and sim_batch_size < num_sims:
        batches = split(theta, sim_batch_size, dim=0)

        if num_workers != 1:
            batch_seeds = randint(high=1_000_000, size=(len(batches),))

            with tqdm_joblib(
                tqdm(batches, disable=not show_progress_bars,
                     desc=f"Running {num_sims} simulations in {len(batches)} batches.", total=len(batches),)) as _:
                simulation_outputs = Parallel(n_jobs=num_workers)(delayed(simulator_seeded)(simulator, batch, batch_seed)
                    for batch, batch_seed in zip(batches, batch_seeds))
        else:
            pbar = tqdm(total=num_sims, disable=not show_progress_bars, desc=f"Running {num_sims} simulations.", )

            with pbar:
                simulation_outputs = []
                for batch in batches:
                    simulation_outputs.append(simulator_seeded(simulator, batch, seed))
                    pbar.update(sim_batch_size)

        x = cat(simulation_outputs, dim=0)
    else:
        x = simulator(theta)

    return x


@contextlib.contextmanager
def tqdm_joblib(tqdm_object):
    def tqdm_print_progress(self):
        if self.n_completed_tasks > tqdm_object.n:
            n_completed = self.n_completed_tasks - tqdm_object.n
            tqdm_object.update(n=n_completed)

    original_print_progress = joblib.parallel.Parallel.print_progress
    joblib.parallel.Parallel.print_progress = tqdm_print_progress

    try:
        yield tqdm_object
    finally:
        joblib.parallel.Parallel.print_progress = original_print_progress
        tqdm_object.close()

def simulate_for_sbi(simulator: Callable, proposal: Any, num_simulations: int, num_workers: int = 1,
                     simulation_batch_size: int = 1, seed: Optional[int] = None,
                     show_progress_bar: bool = True, ) -> Tuple[Tensor, Tensor]:

    theta = proposal.sample((num_simulations,))

    x = simulate_in_batches(simulator=simulator, theta=theta, sim_batch_size=simulation_batch_size,
                            num_workers=num_workers, seed=seed, show_progress_bars=show_progress_bar,)

    return theta, x

######################################################################################################

##################################### PART 2 #########################################################
# pip install sbi
import sbi
from scipy.integrate import odeint
import matplotlib.pyplot as plt
import os

from sbi.inference import SNLE, prepare_for_sbi
# No longer importing simulate_for_sbi from the package, we use the one defined above
from sbi import utils as utils
from sbi import analysis as analysis

#####################################################################################################################

# To run for more parameters, we must 1) add the parameter in the params_to_be_inferred list e.g. params_to_be_inferred = ["k1" , "k2", "k3"] 
#                                     2) add the true value of the new parameter in true_params e.g. true_params = 0, 0, 0
#                                     3) add the parameter in theta in the repressilator function e.g. k1, k2, k3 = theta
#                                     4) ensure the repressilator output accounts for the new parameter e.g. -m3 + (10 ** 3 / (1 + (10 ** k3 * p1) ** 2)) + 10 ** 0
#                                     5) ensure consistency in the order of parameters and values e.g. the order of parameters in the
#                                     params_to_be_inferred list must be the same as their order in the definition of theta within the
#                                     repressilator function, and their order must also be refleccted in true_params

#####################################################################################################################

params_to_be_inferred = ["a1", "k1" , "a2", "k2", "a3", "k3"]
true_params = 3, 0, 3, 0, 3, 0
prior_min = -1                        # same for all parameters
prior_max = 5                         # same for all parameters
num_timesteps = 100
num_rounds = 2                        # how many rounds of SNLE
num_simulations = 50                  # in each round

# To simulate in batches, simulation_batch_size must not be None and simulation_batch_size < num_simulations

simulation_batch_size = 10

# To parallelise, set number of CPUs to be used. Note: parallelise anything that has num_rounds>2 and/or num_simulations>50
# to see total available CPUs: print(os.cpu_count())

CPUs_to_use = 8

#####################################################################################################################

total_CPUs = os.cpu_count()
num_workers = CPUs_to_use - total_CPUs -1
# num_workers = -1 uses all cpus
# num_workers = -2 uses all cpus but one etc https://joblib.readthedocs.io/en/latest/generated/joblib.Parallel.html

if CPUs_to_use > total_CPUs:
    raise ValueError(f"Cannot use more CPUs than are available. Available CPUs: {total_CPUs}")

t = np.linspace(0, 100, num_timesteps)

def my_simulator(theta):
    def repressilator(variables, t, theta):
        m1, p1, m2, p2, m3, p3 = variables
        a1, k1, a2, k2, a3, k3 = theta

        return [-m1 + (10 ** a1 / (1 + (10 ** k1 * p2) ** 2)) + 10 ** 0,
        -10 ** 0 * (p1 - m1),
        -m2 + (10 ** a2 / (1 + (10 ** k2 * p3) ** 2)) + 10 ** 0,
        -10 ** 0 * (p2 - m2),
        -m3 + (10 ** a3 / (1 + (10 ** k3 * p1) ** 2)) + 10 ** 0,
        -10 ** 0 * (p3 - m3)]

    def solve_ode(theta, t):
        initial_conditions = np.array([0, 2, 0, 1, 0, 3], dtype=np.float32)
        solution = odeint(repressilator, initial_conditions, t, args=(theta,))
        return torch.tensor(solution, dtype=torch.float32).flatten() # Flatten tensor to size [600]
    return solve_ode(theta, t)

x_o = my_simulator(true_params) # Generate observations,with data from 100 timepoints for each of 6 variables
                                # concatenated into one tensor (100*6=600)

#####################################################################################################################

num_dim = len(true_params)
prior = utils.BoxUniform(low=prior_min * torch.ones(num_dim), high=prior_max * torch.ones(num_dim))
simulator, prior = prepare_for_sbi(my_simulator, prior)

inference = SNLE(prior) # Initialise inference
posteriors = [] # Empty list to contain posterior after each round
proposal = prior # For the first round proposal = prior, then updated (sequentiality)

for _ in range(num_rounds):
    theta, x = simulate_for_sbi(simulator, proposal, num_simulations = num_simulations, 
                                simulation_batch_size = simulation_batch_size, num_workers=num_workers)
    # sample theta from proposal (=posterior of previus round) using MCMC, and use to simulate data x
    density_estimator = inference.append_simulations(theta, x).train()
    # train neural net using (theta, x) sets
    posterior = inference.build_posterior(density_estimator)
    # generate posterior (proportional to prior*neural estimator)
    posteriors.append(posterior)
    proposal = posterior.set_default_x(x_o) # set posterior = proposal for next round

posterior_samples = posterior.sample((500,), x=x_o) # sample to plot the posteriors

# Plot posteriors
_ = analysis.pairplot(posterior_samples, limits=[[prior_min, prior_max]] * num_dim,
                      figsize=(8, 8), labels = params_to_be_inferred)

##################################### PLOT TRAJECTORIES #############################################################

def plot_trajectories(ax, theta, linestyle='-', color='grey'):
    for param_set in theta:
        traj = my_simulator(param_set).reshape(-1, 6)
        for i in range(6):
            ax.plot(t, traj[:, i], linestyle, color=color, alpha=0.1)

def plot_variables(ax, true_traj, posterior_samples, variables_idx, variables, color_true='blue', color_sim='grey'):
    ax.plot(t, true_traj[:, variables_idx], linestyle='-', color=color_true, label='True trajectory')
    plot_trajectories(ax, theta=posterior_samples, linestyle='--', color=color_sim)
    ax.set_xlabel('t')
    ax.set_ylabel(variables[variables_idx])
    ax.legend()

variables = ["m1", "p1", "m2", "p2", "m3", "p3"]

# Sample final posterior
posterior_samples = posterior.sample((50,), x=x_o) # Adjust the number of samples to avoid confluene

# Plot trajectories
fig, axes = plt.subplots(2, 3, figsize=(15, 10))

for idx, ax in enumerate(axes.flat):
    true_traj = x_o.reshape(-1, 6) # Reshape flattened observation back to the original shape
    plot_variables(ax, true_traj, posterior_samples, variables_idx=idx, variables=variables)

plt.tight_layout()
plt.show()
